{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43f969a9",
   "metadata": {},
   "source": [
    "# Random Forest Classification via cross-validation\n",
    "\n",
    "- classification task: SL (1) or not SL (0)\n",
    "- classification tree can handle all types of data, all types of relationships among the independent variables (the data we're using to make predictions), and all kinds of relationships with the dependent variable (the thing we want to predict)\n",
    "- The column named SL is my target variable (i.e., the variable which I want to predict). There are two possible classes: 0 (non-SL) and 1 (SL). The resulting prediction problem is therefore a binary classification problem, while I will use the other columns (feature columns) as input variables for the model.\n",
    "\n",
    "*StratifiedKFold* is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.\n",
    "\n",
    "*StratifiedKFold* preserves the class ratios (approximately 1 / 10) in both train and test dataset.\n",
    "\n",
    "*StratifiedGroupKFold* is used to generate the train and test sets for model 2 and model 3\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html#sklearn.model_selection.StratifiedGroupKFold\n",
    "\n",
    "The implementation is designed to:\n",
    "- Generate test sets such that all contain the same distribution of classes, or as close as possible.\n",
    "- Be invariant to class label: relabelling y = [\"Happy\", \"Sad\"] to y = [1, 0] should not change the indices generated.\n",
    "- Preserve order dependencies in the dataset ordering, when shuffle=False: all samples from class k in some test set were contiguous in y, or separated in y by samples from classes other than k.\n",
    "- Generate test sets where the smallest and largest differ by at most one sample.\n",
    "\n",
    "*type_of_target* : Determine the type of data indicated by the target, binary, multiclass, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d6b2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# import scikit-learn modules\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, roc_auc_score, average_precision_score, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "# import visualization modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d920513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path\n",
    "get_data_path = lambda folders, fname: os.path.normpath(os.environ['DRIVE_PATH'] + '/' + '/'.join(folders) + '/' + fname)\n",
    "\n",
    "file_path = get_data_path(['SL PRED', 'NEW'], 'ito_pairs_annotated.csv')\n",
    "old_classifier_path = get_data_path(['SL PRED', 'input'], 'processed_DeKegel_TableS8.csv')\n",
    "\n",
    "# Output\n",
    "file_RF_model_I_early = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_I'], 'RF_model_early.pickle')\n",
    "file_RF_model_I_late = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_I'], 'RF_model_late.pickle')\n",
    "#file_RF_model_I_early_repeated = get_data_path(['SL PRED', 'output', 'NEW', 'cross_validation', 'model_I'], 'RF_model_early_repeated.pickle')\n",
    "#file_RF_model_I_late_repeated = get_data_path(['SL PRED', 'output', 'NEW', 'cross_validation', 'model_I'], 'RF_model_late_repeated.pickle')\n",
    "#file_RF_model_I_early_reduced = get_data_path(['SL PRED', 'output', 'NEW', 'cross_validation', 'model_I'], 'RF_model_early_reduced.pickle')\n",
    "#file_RF_model_I_late_reduced = get_data_path(['SL PRED', 'output', 'NEW', 'cross_validation', 'model_I'], 'RF_model_late_reduced.pickle')\n",
    "\n",
    "file_RF_model_II_early = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_II'], 'RF_model_early.pickle')\n",
    "file_RF_model_II_late = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_II'], 'RF_model_late.pickle')\n",
    "#file_RF_model_II_early_repeated = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_II'], 'RF_model_early_repeated.pickle')\n",
    "#file_RF_model_II_late_repeated = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_II'], 'RF_model_late_repeated.pickle')\n",
    "#file_RF_model_II_early_reduced = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_II'], 'RF_model_early_reduced.pickle')\n",
    "#file_RF_model_II_late_reduced= get_data_path(['SL PRED', 'output', 'cross_validation', 'model_II'], 'RF_model_late_reduced.pickle')\n",
    "\n",
    "file_RF_model_III_early = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_III'], 'RF_model_early.pickle')\n",
    "file_RF_model_III_late = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_III'], 'RF_model_late.pickle')\n",
    "#file_RF_model_III_early_repeated = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_III'], 'RF_model_early_repeated.pickle')\n",
    "#file_RF_model_III_late_repeated = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_III'], 'RF_model_late_repeated.pickle')\n",
    "#file_RF_model_III_early_reduced = get_data_path(['SL PRED', 'output', 'cross_validation', 'model_III'], 'RF_model_early_reduced.pickle')\n",
    "#file_RF_model_III_late_reduced= get_data_path(['SL PRED', 'output', 'cross_validation', 'model_III'], 'RF_model_late_reduced.pickle')\n",
    "\n",
    "file_RF_model_IV_early = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_IV'], 'RF_model_early.pickle')\n",
    "file_RF_model_IV_late = get_data_path(['SL PRED', 'NEW', 'imputation', 'cross_validation', 'model_IV'], 'RF_model_late.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1c4071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>Gemini_FDR</th>\n",
       "      <th>raw_LFC</th>\n",
       "      <th>SL</th>\n",
       "      <th>...</th>\n",
       "      <th>A2_rank</th>\n",
       "      <th>zA2_rank</th>\n",
       "      <th>max_ranked_A1A2</th>\n",
       "      <th>min_ranked_A1A2</th>\n",
       "      <th>z_max_ranked_A1A2</th>\n",
       "      <th>z_min_ranked_A1A2</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>GEMINI</th>\n",
       "      <th>LFC</th>\n",
       "      <th>SL_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000022</td>\n",
       "      <td>PATU8988S_PANCREAS</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>-0.759628</td>\n",
       "      <td>-0.759628</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.118768</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000307</td>\n",
       "      <td>PK1_PANCREAS</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000632</td>\n",
       "      <td>HS944T_SKIN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-1.036177</td>\n",
       "      <td>-1.036177</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000681</td>\n",
       "      <td>A549_LUNG</td>\n",
       "      <td>0.977988</td>\n",
       "      <td>0.379455</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15434.0</td>\n",
       "      <td>15434.0</td>\n",
       "      <td>1.973047</td>\n",
       "      <td>1.973047</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>-0.241323</td>\n",
       "      <td>0.379455</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000756</td>\n",
       "      <td>GI1_CENTRAL_NERVOUS_SYSTEM</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>-0.077118</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6507.0</td>\n",
       "      <td>6507.0</td>\n",
       "      <td>-0.389397</td>\n",
       "      <td>-0.389397</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.299715</td>\n",
       "      <td>-0.077118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genepair       A1   A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
       "0  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000022   \n",
       "1  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000307   \n",
       "2  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000632   \n",
       "3  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000681   \n",
       "4  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000756   \n",
       "\n",
       "                    cell_line  Gemini_FDR   raw_LFC     SL  ... A2_rank  \\\n",
       "0          PATU8988S_PANCREAS    0.998944  0.088856  False  ...     NaN   \n",
       "1                PK1_PANCREAS    0.986587  0.201704  False  ...     NaN   \n",
       "2                 HS944T_SKIN    1.000000  0.069772  False  ...     NaN   \n",
       "3                   A549_LUNG    0.977988  0.379455  False  ...     NaN   \n",
       "4  GI1_CENTRAL_NERVOUS_SYSTEM    0.999586 -0.077118  False  ...     NaN   \n",
       "\n",
       "  zA2_rank  max_ranked_A1A2  min_ranked_A1A2  z_max_ranked_A1A2  \\\n",
       "0      NaN           5108.0           5108.0          -0.759628   \n",
       "1      NaN           9125.0           9125.0           0.303431   \n",
       "2      NaN           4063.0           4063.0          -1.036177   \n",
       "3      NaN          15434.0          15434.0           1.973047   \n",
       "4      NaN           6507.0           6507.0          -0.389397   \n",
       "\n",
       "   z_min_ranked_A1A2  prediction_score    GEMINI       LFC  SL_new  \n",
       "0          -0.759628          0.012559  0.118768  0.088856   False  \n",
       "1           0.303431          0.012559  0.132501  0.201704   False  \n",
       "2          -1.036177          0.012559  0.024593  0.069772   False  \n",
       "3           1.973047          0.012559 -0.241323  0.379455   False  \n",
       "4          -0.389397          0.012559  0.299715 -0.077118   False  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(file_path)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c542d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_rank</th>\n",
       "      <th>prediction_percentile</th>\n",
       "      <th>old_genepair</th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>A1_ensembl</th>\n",
       "      <th>A2_ensembl</th>\n",
       "      <th>...</th>\n",
       "      <th>shared_ppi_mean_essentiality</th>\n",
       "      <th>gtex_spearman_corr</th>\n",
       "      <th>gtex_min_mean_expr</th>\n",
       "      <th>gtex_max_mean_expr</th>\n",
       "      <th>A1_entrez_new</th>\n",
       "      <th>A2_entrez_new</th>\n",
       "      <th>A1_new</th>\n",
       "      <th>A2_new</th>\n",
       "      <th>A1_ensembl_new</th>\n",
       "      <th>A2_ensembl_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>SMARCA2_SMARCA4</td>\n",
       "      <td>SMARCA2_SMARCA4</td>\n",
       "      <td>SMARCA2</td>\n",
       "      <td>SMARCA4</td>\n",
       "      <td>6595</td>\n",
       "      <td>6597</td>\n",
       "      <td>ENSG00000080503</td>\n",
       "      <td>ENSG00000127616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225382</td>\n",
       "      <td>0.627875</td>\n",
       "      <td>18.609973</td>\n",
       "      <td>34.302868</td>\n",
       "      <td>6595.0</td>\n",
       "      <td>6597</td>\n",
       "      <td>SMARCA2</td>\n",
       "      <td>SMARCA4</td>\n",
       "      <td>ENSG00000080503</td>\n",
       "      <td>ENSG00000127616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EXOC6_EXOC6B</td>\n",
       "      <td>EXOC6_EXOC6B</td>\n",
       "      <td>EXOC6</td>\n",
       "      <td>EXOC6B</td>\n",
       "      <td>54536</td>\n",
       "      <td>23233</td>\n",
       "      <td>ENSG00000138190</td>\n",
       "      <td>ENSG00000144036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285886</td>\n",
       "      <td>0.069456</td>\n",
       "      <td>6.390812</td>\n",
       "      <td>11.168367</td>\n",
       "      <td>54536.0</td>\n",
       "      <td>23233</td>\n",
       "      <td>EXOC6</td>\n",
       "      <td>EXOC6B</td>\n",
       "      <td>ENSG00000138190</td>\n",
       "      <td>ENSG00000144036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>STAG1_STAG2</td>\n",
       "      <td>STAG1_STAG2</td>\n",
       "      <td>STAG1</td>\n",
       "      <td>STAG2</td>\n",
       "      <td>10274</td>\n",
       "      <td>10735</td>\n",
       "      <td>ENSG00000118007</td>\n",
       "      <td>ENSG00000101972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329993</td>\n",
       "      <td>0.854086</td>\n",
       "      <td>13.103716</td>\n",
       "      <td>22.097616</td>\n",
       "      <td>10274.0</td>\n",
       "      <td>10735</td>\n",
       "      <td>STAG1</td>\n",
       "      <td>STAG2</td>\n",
       "      <td>ENSG00000118007</td>\n",
       "      <td>ENSG00000101972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_rank  prediction_percentile     old_genepair         genepair  \\\n",
       "0                1                    0.1  SMARCA2_SMARCA4  SMARCA2_SMARCA4   \n",
       "1                2                    0.1     EXOC6_EXOC6B     EXOC6_EXOC6B   \n",
       "2                3                    0.1      STAG1_STAG2      STAG1_STAG2   \n",
       "\n",
       "        A1       A2  A1_entrez  A2_entrez       A1_ensembl       A2_ensembl  \\\n",
       "0  SMARCA2  SMARCA4       6595       6597  ENSG00000080503  ENSG00000127616   \n",
       "1    EXOC6   EXOC6B      54536      23233  ENSG00000138190  ENSG00000144036   \n",
       "2    STAG1    STAG2      10274      10735  ENSG00000118007  ENSG00000101972   \n",
       "\n",
       "   ...  shared_ppi_mean_essentiality  gtex_spearman_corr  gtex_min_mean_expr  \\\n",
       "0  ...                      0.225382            0.627875           18.609973   \n",
       "1  ...                      0.285886            0.069456            6.390812   \n",
       "2  ...                      0.329993            0.854086           13.103716   \n",
       "\n",
       "   gtex_max_mean_expr A1_entrez_new  A2_entrez_new   A1_new   A2_new  \\\n",
       "0           34.302868        6595.0           6597  SMARCA2  SMARCA4   \n",
       "1           11.168367       54536.0          23233    EXOC6   EXOC6B   \n",
       "2           22.097616       10274.0          10735    STAG1    STAG2   \n",
       "\n",
       "    A1_ensembl_new   A2_ensembl_new  \n",
       "0  ENSG00000080503  ENSG00000127616  \n",
       "1  ENSG00000138190  ENSG00000144036  \n",
       "2  ENSG00000118007  ENSG00000101972  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_classifier_training_df = pd.read_csv(old_classifier_path)\n",
    "old_classifier_training_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4d97208",
   "metadata": {},
   "outputs": [],
   "source": [
    "late_features_df = old_classifier_training_df[['genepair', 'A1_entrez_new', 'A2_entrez_new', 'min_sequence_identity', 'closest', 'WGD', 'family_size', 'cds_length_ratio', 'shared_domains', 'has_pombe_ortholog',\n",
    "                                            'has_essential_pombe_ortholog', 'has_cerevisiae_ortholog', 'has_essential_cerevisiae_ortholog', 'conservation_score', 'mean_age', 'either_in_complex', 'mean_complex_essentiality', 'colocalisation',\n",
    "                                            'interact', 'n_total_ppi', 'fet_ppi_overlap','gtex_spearman_corr', 'gtex_min_mean_expr', 'gtex_max_mean_expr']]\n",
    "late_features_df = late_features_df.rename(columns={'A1_entrez_new':'A1_entrez', 'A2_entrez_new': 'A2_entrez'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "02fdcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_features(df, features_df):\n",
    "    integrated_df = pd.merge(df, features_df, \n",
    "                             left_on=['genepair', 'A1_entrez', 'A2_entrez'], \n",
    "                             right_on=['genepair', 'A1_entrez', 'A2_entrez'], \n",
    "                             how='left')\n",
    "    bool_cols = ['closest', 'WGD', 'has_pombe_ortholog', 'has_essential_cerevisiae_ortholog', 'either_in_complex', 'interact']\n",
    "    integrated_df[bool_cols] = integrated_df[bool_cols].astype(bool)\n",
    "    return integrated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "131b5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>Gemini_FDR</th>\n",
       "      <th>raw_LFC</th>\n",
       "      <th>SL</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>either_in_complex</th>\n",
       "      <th>mean_complex_essentiality</th>\n",
       "      <th>colocalisation</th>\n",
       "      <th>interact</th>\n",
       "      <th>n_total_ppi</th>\n",
       "      <th>fet_ppi_overlap</th>\n",
       "      <th>gtex_spearman_corr</th>\n",
       "      <th>gtex_min_mean_expr</th>\n",
       "      <th>gtex_max_mean_expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000022</td>\n",
       "      <td>PATU8988S_PANCREAS</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000307</td>\n",
       "      <td>PK1_PANCREAS</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000632</td>\n",
       "      <td>HS944T_SKIN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genepair       A1   A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
       "0  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000022   \n",
       "1  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000307   \n",
       "2  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000632   \n",
       "\n",
       "            cell_line  Gemini_FDR   raw_LFC     SL  ... mean_age  \\\n",
       "0  PATU8988S_PANCREAS    0.998944  0.088856  False  ...    226.1   \n",
       "1        PK1_PANCREAS    0.986587  0.201704  False  ...    226.1   \n",
       "2         HS944T_SKIN    1.000000  0.069772  False  ...    226.1   \n",
       "\n",
       "  either_in_complex  mean_complex_essentiality  colocalisation  interact  \\\n",
       "0             False                        0.0             0.0     False   \n",
       "1             False                        0.0             0.0     False   \n",
       "2             False                        0.0             0.0     False   \n",
       "\n",
       "   n_total_ppi  fet_ppi_overlap  gtex_spearman_corr  gtex_min_mean_expr  \\\n",
       "0          3.0              0.0            0.114847            0.258739   \n",
       "1          3.0              0.0            0.114847            0.258739   \n",
       "2          3.0              0.0            0.114847            0.258739   \n",
       "\n",
       "   gtex_max_mean_expr  \n",
       "0              11.702  \n",
       "1              11.702  \n",
       "2              11.702  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_training_df = integrate_features(training_df, late_features_df)\n",
    "integrated_training_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d41d86e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features: 16\n"
     ]
    }
   ],
   "source": [
    "feature_columns_1 = ['rMaxExp_A1A2', 'rMinExp_A1A2',\n",
    "                     'max_ranked_A1A2', 'min_ranked_A1A2',\n",
    "                     'max_cn', 'min_cn', 'Protein_Altering', 'Damaging', \n",
    "                     'min_sequence_identity',\n",
    "                     'prediction_score', \n",
    "                     'ranked_Essentiality_weighted_PPI', 'Expression_weighted_PPI',\n",
    "                     'smallest_GO_ranked_ess', 'smallest_GO_CC_ranked_ess',\n",
    "                     'smallest_gene_expression', 'smallest_GO_CC_expression'\n",
    "                     ]\n",
    "\n",
    "target_column = 'SL_new'\n",
    "\n",
    "print('num of features:', len(feature_columns_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eabb29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features: 35\n"
     ]
    }
   ],
   "source": [
    "feature_columns_2 = feature_columns_1 + ['closest', 'WGD', 'family_size',\n",
    "                                         'cds_length_ratio', 'shared_domains', 'has_pombe_ortholog',\n",
    "                                         'has_essential_pombe_ortholog', 'has_cerevisiae_ortholog', 'has_essential_cerevisiae_ortholog', \n",
    "                                         'conservation_score', 'mean_age', 'either_in_complex', 'mean_complex_essentiality', 'colocalisation',\n",
    "                                         'interact', 'n_total_ppi', 'fet_ppi_overlap',\n",
    "                                         'gtex_spearman_corr', 'gtex_min_mean_expr', 'gtex_max_mean_expr']\n",
    "feature_columns_2.remove('prediction_score')\n",
    "print('num of features:', len(feature_columns_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea5be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_values = integrated_training_df[feature_columns_1].isna().sum() / len(integrated_training_df) * 100\n",
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08154f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rMaxExp_A1A2                           11\n",
       "rMinExp_A1A2                           11\n",
       "max_ranked_A1A2                      4926\n",
       "min_ranked_A1A2                      4926\n",
       "max_cn                                  5\n",
       "min_cn                                  5\n",
       "Protein_Altering                        0\n",
       "Damaging                                0\n",
       "min_sequence_identity                3347\n",
       "prediction_score                     3347\n",
       "ranked_Essentiality_weighted_PPI     7901\n",
       "Expression_weighted_PPI              3793\n",
       "smallest_GO_ranked_ess              26137\n",
       "smallest_GO_CC_ranked_ess           40788\n",
       "smallest_gene_expression            23970\n",
       "smallest_GO_CC_expression           39944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_training_df[feature_columns_1].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd20498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rMaxExp_A1A2                            11\n",
       "rMinExp_A1A2                            11\n",
       "max_ranked_A1A2                       4926\n",
       "min_ranked_A1A2                       4926\n",
       "max_cn                                   5\n",
       "min_cn                                   5\n",
       "Protein_Altering                         0\n",
       "Damaging                                 0\n",
       "min_sequence_identity                 3347\n",
       "ranked_Essentiality_weighted_PPI      7901\n",
       "Expression_weighted_PPI               3793\n",
       "smallest_GO_ranked_ess               26137\n",
       "smallest_GO_CC_ranked_ess            40788\n",
       "smallest_gene_expression             23970\n",
       "smallest_GO_CC_expression            39944\n",
       "closest                                  0\n",
       "WGD                                      0\n",
       "family_size                           3347\n",
       "cds_length_ratio                      3347\n",
       "shared_domains                        3347\n",
       "has_pombe_ortholog                       0\n",
       "has_essential_pombe_ortholog          3347\n",
       "has_cerevisiae_ortholog               3347\n",
       "has_essential_cerevisiae_ortholog        0\n",
       "conservation_score                    3347\n",
       "mean_age                              3347\n",
       "either_in_complex                        0\n",
       "mean_complex_essentiality             3347\n",
       "colocalisation                        3347\n",
       "interact                                 0\n",
       "n_total_ppi                           3347\n",
       "fet_ppi_overlap                       3347\n",
       "gtex_spearman_corr                    3347\n",
       "gtex_min_mean_expr                    3347\n",
       "gtex_max_mean_expr                    3347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_training_df[feature_columns_2].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c36ac693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, old_df,\n",
    "                       required_genepairs_col='genepair',\n",
    "                       dropna_cols=None,\n",
    "                       fillna_zero_cols=None,\n",
    "                       fillna_large_cols=None,\n",
    "                       fillna_large_value=18000):\n",
    "    \"\"\"\n",
    "    Preprocess a training or testing dataset:\n",
    "    - Keep only rows with genepairs present in `old_df`\n",
    "    - Drop rows with NaN in specific columns\n",
    "    - Fill missing values with default values\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Dataset to process\n",
    "        old_df (pd.DataFrame): Dataset with allowed genepairs\n",
    "        required_genepairs_col (str): Column name for genepairs to match\n",
    "        dropna_cols (list): Columns for which rows with NaNs should be dropped\n",
    "        fillna_zero_cols (list): Columns to fill NaNs with 0\n",
    "        fillna_large_cols (list): Columns to fill NaNs with large constant\n",
    "        fillna_large_value (int or float): The large value to fill (default: 18000)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and processed DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Filter rows to only those in old_df\n",
    "    df_filtered = df[df[required_genepairs_col].isin(old_df[required_genepairs_col])].copy()\n",
    "\n",
    "    # Step 2: Drop rows with any NA in required columns\n",
    "    if dropna_cols:\n",
    "        df_filtered = df_filtered.dropna(axis=0, how='any', subset=dropna_cols)\n",
    "\n",
    "    # Step 3: Fill NaNs with 0 or large number\n",
    "    if fillna_zero_cols:\n",
    "        df_filtered[fillna_zero_cols] = df_filtered[fillna_zero_cols].fillna(0)\n",
    "\n",
    "    if fillna_large_cols:\n",
    "        df_filtered[fillna_large_cols] = df_filtered[fillna_large_cols].fillna(fillna_large_value)\n",
    "\n",
    "    # Step 4: Reset index for clean result\n",
    "    return df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11357c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na_values = ['rMaxExp_A1A2', 'rMinExp_A1A2', 'max_ranked_A1A2', 'min_ranked_A1A2']\n",
    "fillna_values = ['Expression_weighted_PPI', 'smallest_gene_expression', 'smallest_GO_CC_expression']\n",
    "fillna_values_v2 = ['ranked_Essentiality_weighted_PPI', 'smallest_GO_ranked_ess', 'smallest_GO_CC_ranked_ess']\n",
    "\n",
    "# Apply to training set\n",
    "integrated_training_df_clean = preprocess_dataset(\n",
    "    df=integrated_training_df,\n",
    "    old_df=old_classifier_training_df,\n",
    "    dropna_cols=drop_na_values,\n",
    "    fillna_zero_cols=fillna_values,\n",
    "    fillna_large_cols=fillna_values_v2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a554b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_values = integrated_training_df[feature_columns_2].isna().sum() / len(integrated_training_df) * 100\n",
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5c74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>Gemini_FDR</th>\n",
       "      <th>raw_LFC</th>\n",
       "      <th>SL</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>either_in_complex</th>\n",
       "      <th>mean_complex_essentiality</th>\n",
       "      <th>colocalisation</th>\n",
       "      <th>interact</th>\n",
       "      <th>n_total_ppi</th>\n",
       "      <th>fet_ppi_overlap</th>\n",
       "      <th>gtex_spearman_corr</th>\n",
       "      <th>gtex_min_mean_expr</th>\n",
       "      <th>gtex_max_mean_expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000022</td>\n",
       "      <td>PATU8988S_PANCREAS</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000307</td>\n",
       "      <td>PK1_PANCREAS</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000632</td>\n",
       "      <td>HS944T_SKIN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>226.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genepair       A1   A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
       "0  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000022   \n",
       "1  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000307   \n",
       "2  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000632   \n",
       "\n",
       "            cell_line  Gemini_FDR   raw_LFC     SL  ... mean_age  \\\n",
       "0  PATU8988S_PANCREAS    0.998944  0.088856  False  ...    226.1   \n",
       "1        PK1_PANCREAS    0.986587  0.201704  False  ...    226.1   \n",
       "2         HS944T_SKIN    1.000000  0.069772  False  ...    226.1   \n",
       "\n",
       "  either_in_complex  mean_complex_essentiality  colocalisation  interact  \\\n",
       "0             False                        0.0             0.0     False   \n",
       "1             False                        0.0             0.0     False   \n",
       "2             False                        0.0             0.0     False   \n",
       "\n",
       "   n_total_ppi  fet_ppi_overlap  gtex_spearman_corr  gtex_min_mean_expr  \\\n",
       "0          3.0              0.0            0.114847            0.258739   \n",
       "1          3.0              0.0            0.114847            0.258739   \n",
       "2          3.0              0.0            0.114847            0.258739   \n",
       "\n",
       "   gtex_max_mean_expr  \n",
       "0              11.702  \n",
       "1              11.702  \n",
       "2              11.702  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_training_df_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f67061c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num SL: 958 / 41244\n",
      "Num non-SL: 40286 / 41244\n",
      "Number of unique gene pairs: 4170\n",
      "Number of unique cell lines: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>Gemini_FDR</th>\n",
       "      <th>raw_LFC</th>\n",
       "      <th>SL</th>\n",
       "      <th>...</th>\n",
       "      <th>A2_rank</th>\n",
       "      <th>zA2_rank</th>\n",
       "      <th>max_ranked_A1A2</th>\n",
       "      <th>min_ranked_A1A2</th>\n",
       "      <th>z_max_ranked_A1A2</th>\n",
       "      <th>z_min_ranked_A1A2</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>GEMINI</th>\n",
       "      <th>LFC</th>\n",
       "      <th>SL_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000022</td>\n",
       "      <td>PATU8988S_PANCREAS</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>-0.759628</td>\n",
       "      <td>-0.759628</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.118768</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000307</td>\n",
       "      <td>PK1_PANCREAS</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000632</td>\n",
       "      <td>HS944T_SKIN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-1.036177</td>\n",
       "      <td>-1.036177</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genepair       A1   A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
       "0  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000022   \n",
       "1  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000307   \n",
       "2  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000632   \n",
       "\n",
       "            cell_line  Gemini_FDR   raw_LFC     SL  ... A2_rank zA2_rank  \\\n",
       "0  PATU8988S_PANCREAS    0.998944  0.088856  False  ...     NaN      NaN   \n",
       "1        PK1_PANCREAS    0.986587  0.201704  False  ...     NaN      NaN   \n",
       "2         HS944T_SKIN    1.000000  0.069772  False  ...     NaN      NaN   \n",
       "\n",
       "   max_ranked_A1A2  min_ranked_A1A2  z_max_ranked_A1A2  z_min_ranked_A1A2  \\\n",
       "0           5108.0           5108.0          -0.759628          -0.759628   \n",
       "1           9125.0           9125.0           0.303431           0.303431   \n",
       "2           4063.0           4063.0          -1.036177          -1.036177   \n",
       "\n",
       "   prediction_score    GEMINI       LFC  SL_new  \n",
       "0          0.012559  0.118768  0.088856   False  \n",
       "1          0.012559  0.132501  0.201704   False  \n",
       "2          0.012559  0.024593  0.069772   False  \n",
       "\n",
       "[3 rows x 62 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of the training dataset after removing NA values\n",
    "print('Num SL:', integrated_training_df_clean[integrated_training_df_clean[target_column] == True].shape[0], '/', integrated_training_df_clean.shape[0])\n",
    "print('Num non-SL:', integrated_training_df_clean[integrated_training_df_clean[target_column] == False].shape[0], '/', integrated_training_df_clean.shape[0])\n",
    "print(f'Number of unique gene pairs: {integrated_training_df_clean.genepair.nunique()}')\n",
    "print(f'Number of unique cell lines: {integrated_training_df_clean.cell_line.nunique()}')\n",
    "training_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cfd3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_training_df_clean.to_csv(get_data_path(['SL PRED', 'NEW'], 'data_SL_pred.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9610e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute_features = ['ranked_Essentiality_weighted_PPI', 'Expression_weighted_PPI', 'smallest_GO_ranked_ess', 'smallest_GO_CC_ranked_ess', 'smallest_gene_expression', 'smallest_GO_CC_expression']\n",
    "\n",
    "#integrated_training_df_clean = integrated_training_df.copy()\n",
    "\n",
    "#integrated_training_df_clean[impute_features] = integrated_training_df_clean.groupby(\"DepMap_ID\")[impute_features].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bd78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrated_training_df_clean.loc[integrated_training_df_clean['max_ranked_A1A2'].isna(), ['genepair','cell_line','max_ranked_A1A2', 'min_ranked_A1A2', 'ranked_Essentiality_weighted_PPI', 'smallest_GO_ranked_ess']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979695a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num SL: 946 / 41114\n",
      "Num non-SL: 40168 / 41114\n",
      "Number of unique gene pairs: 4157\n",
      "Number of unique cell lines: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genepair</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A1_entrez</th>\n",
       "      <th>A2_entrez</th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>Gemini_FDR</th>\n",
       "      <th>raw_LFC</th>\n",
       "      <th>SL</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_complex_essentiality</th>\n",
       "      <th>colocalisation</th>\n",
       "      <th>interact</th>\n",
       "      <th>n_total_ppi</th>\n",
       "      <th>fet_ppi_overlap</th>\n",
       "      <th>gtex_spearman_corr</th>\n",
       "      <th>gtex_min_mean_expr</th>\n",
       "      <th>gtex_max_mean_expr</th>\n",
       "      <th>min_sequence_identity</th>\n",
       "      <th>shared_ppi_mean_essentiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000022</td>\n",
       "      <td>PATU8988S_PANCREAS</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.088856</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000307</td>\n",
       "      <td>PK1_PANCREAS</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3GALT2_ABO</td>\n",
       "      <td>A3GALT2</td>\n",
       "      <td>ABO</td>\n",
       "      <td>127550</td>\n",
       "      <td>28</td>\n",
       "      <td>ACH-000632</td>\n",
       "      <td>HS944T_SKIN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069772</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114847</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>11.702</td>\n",
       "      <td>0.340483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genepair       A1   A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
       "0  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000022   \n",
       "1  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000307   \n",
       "2  A3GALT2_ABO  A3GALT2  ABO     127550         28  ACH-000632   \n",
       "\n",
       "            cell_line  Gemini_FDR   raw_LFC     SL  ...  \\\n",
       "0  PATU8988S_PANCREAS    0.998944  0.088856  False  ...   \n",
       "1        PK1_PANCREAS    0.986587  0.201704  False  ...   \n",
       "2         HS944T_SKIN    1.000000  0.069772  False  ...   \n",
       "\n",
       "  mean_complex_essentiality colocalisation  interact  n_total_ppi  \\\n",
       "0                       0.0            0.0     False          3.0   \n",
       "1                       0.0            0.0     False          3.0   \n",
       "2                       0.0            0.0     False          3.0   \n",
       "\n",
       "   fet_ppi_overlap  gtex_spearman_corr  gtex_min_mean_expr  \\\n",
       "0              0.0            0.114847            0.258739   \n",
       "1              0.0            0.114847            0.258739   \n",
       "2              0.0            0.114847            0.258739   \n",
       "\n",
       "   gtex_max_mean_expr  min_sequence_identity  shared_ppi_mean_essentiality  \n",
       "0              11.702               0.340483                           0.0  \n",
       "1              11.702               0.340483                           0.0  \n",
       "2              11.702               0.340483                           0.0  \n",
       "\n",
       "[3 rows x 84 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove NA values before training the model\n",
    "#integrated_training_df_clean = integrated_training_df_clean.dropna(axis=0, how='any', subset=feature_columns_2 + [target_column]).reset_index(drop=True) \n",
    "\n",
    "#integrated_training_df_clean = integrated_training_df.copy()\n",
    "\n",
    "#summary of the training dataset after removing NA values\n",
    "#print('Num SL:', integrated_training_df_clean[integrated_training_df_clean[target_column] == True].shape[0], '/', integrated_training_df_clean.shape[0])\n",
    "#print('Num non-SL:', integrated_training_df_clean[integrated_training_df_clean[target_column] == False].shape[0], '/', integrated_training_df_clean.shape[0])\n",
    "#print(f'Number of unique gene pairs: {integrated_training_df_clean.genepair.nunique()}')\n",
    "#print(f'Number of unique cell lines: {integrated_training_df_clean.cell_line.nunique()}')\n",
    "#integrated_training_df_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bf1b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rMaxExp_A1A2                        0\n",
       "rMinExp_A1A2                        0\n",
       "max_ranked_A1A2                     0\n",
       "min_ranked_A1A2                     0\n",
       "max_cn                              0\n",
       "min_cn                              0\n",
       "Protein_Altering                    0\n",
       "Damaging                            0\n",
       "min_sequence_identity               0\n",
       "prediction_score                    0\n",
       "ranked_Essentiality_weighted_PPI    0\n",
       "Expression_weighted_PPI             0\n",
       "smallest_GO_ranked_ess              0\n",
       "smallest_GO_CC_ranked_ess           0\n",
       "smallest_gene_expression            0\n",
       "smallest_GO_CC_expression           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_training_df_clean[feature_columns_1].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5bd4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_values = integrated_training_df_clean[feature_columns_1].isna().sum() / len(integrated_training_df_clean) * 100\n",
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrated_training_df_clean.to_csv(get_data_path(['SL PRED', 'output', 'NEW'], 'integrated_training_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f751d",
   "metadata": {},
   "source": [
    "### Model I - Random Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad94ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_roc_auc(y_true, y_score):\n",
    "    mask = ~np.isnan(y_score)\n",
    "    if np.sum(mask) < 2 or len(np.unique(y_true[mask])) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true[mask], y_score[mask])\n",
    "\n",
    "def safe_average_precision(y_true, y_score):\n",
    "    mask = ~np.isnan(y_score)\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return average_precision_score(y_true[mask], y_score[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc769690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_early_cross_validation(classifier, data, target, splits, verbose=True):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    pred_aucs, seq_aucs, gene_expr_aucs, gene_ess_aucs = [], [], [], []\n",
    "    aps, pred_aps, seq_aps, gene_expr_aps, gene_ess_aps = [], [], [], [], []\n",
    "\n",
    "    y_real = []\n",
    "    y_proba = []\n",
    "\n",
    "    total_splits = len(splits)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for fold_num, (train, test) in enumerate(splits, start=1):\n",
    "        print(f\"Fold {fold_num}: Train size = {len(train)}, Test size = {len(test)}\")\n",
    "\n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        y_test = target.iloc[test].values\n",
    "        y_pred_proba = classifier.fit(data.iloc[train], target.iloc[train]).predict_proba(data.iloc[test])[:, 1]\n",
    "\n",
    "        if np.unique(y_test).size < 2:\n",
    "            print(f\"Skipping fold {fold_num} due to insufficient positive/negative samples.\")\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "\n",
    "        aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "        aps.append(average_precision_score(y_test, y_pred_proba))\n",
    "\n",
    "        # Scores from input data columns\n",
    "        pred_aucs.append(safe_roc_auc(y_test, data.iloc[test]['prediction_score'].values))\n",
    "        seq_aucs.append(safe_roc_auc(y_test, data.iloc[test]['min_sequence_identity'].values))\n",
    "        gene_expr_aucs.append(safe_roc_auc(y_test, data.iloc[test]['rMinExp_A1A2'].values))\n",
    "        gene_ess_aucs.append(1 - safe_roc_auc(y_test, data.iloc[test]['min_ranked_A1A2'].values))\n",
    "\n",
    "        pred_aps.append(safe_average_precision(y_test, data.iloc[test]['prediction_score'].values))\n",
    "        seq_aps.append(safe_average_precision(y_test, data.iloc[test]['min_sequence_identity'].values))\n",
    "        gene_expr_aps.append(safe_average_precision(y_test, data.iloc[test]['rMinExp_A1A2'].values))\n",
    "        gene_ess_aps.append(safe_average_precision(y_test, data.iloc[test]['min_ranked_A1A2'].values))\n",
    "\n",
    "        y_real.append(y_test)\n",
    "        y_proba.append(y_pred_proba)\n",
    "\n",
    "        if verbose:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Fold {fold_num}/{total_splits} complete: ROC AUC = {aucs[-1]:.4f}, \"\n",
    "                  f\"Elapsed time = {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    if len(tprs) > 0:\n",
    "        mean_tpr = np.mean([np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(tprs))], axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "    else:\n",
    "        mean_tpr, mean_auc, std_auc = np.array([]), np.nan, np.nan\n",
    "\n",
    "    if len(y_real) > 0 and len(y_proba) > 0:\n",
    "        y_real = np.concatenate(y_real)\n",
    "        y_proba = np.concatenate(y_proba)\n",
    "        precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "    else:\n",
    "        precision, recall = np.array([]), np.array([])\n",
    "\n",
    "    if verbose and not np.isnan(mean_auc):\n",
    "        print(f\"Cross-validation complete: Mean ROC AUC = {mean_auc:.4f}, Std ROC AUC = {std_auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'tprs': tprs, 'fprs': fprs, 'aucs': aucs,\n",
    "        'mean_tpr': mean_tpr, 'mean_fpr': mean_fpr, 'mean_auc': mean_auc, 'std_auc': std_auc,\n",
    "        'seq_auc': np.nanmean(seq_aucs), 'seq_std_auc': np.nanstd(seq_aucs),\n",
    "        'pred_auc': np.nanmean(pred_aucs), 'pred_std_auc': np.nanstd(pred_aucs),\n",
    "        'gene_expr_auc': np.nanmean(gene_expr_aucs), 'gene_expr_std_auc': np.nanstd(gene_expr_aucs),\n",
    "        'gene_ess_auc': np.nanmean(gene_ess_aucs), 'gene_ess_std_auc': np.nanstd(gene_ess_aucs),\n",
    "        'precision': precision, 'recall': recall, 'aps': aps,\n",
    "        'mean_aps': np.nanmean(aps), 'std_ap': np.nanstd(aps),\n",
    "        'pred_ap': np.nanmean(pred_aps), 'pred_std_ap': np.nanstd(pred_aps),\n",
    "        'seq_ap': np.nanmean(seq_aps), 'seq_std_ap': np.nanstd(seq_aps),\n",
    "        'gene_expr_ap': np.nanmean(gene_expr_aps), 'gene_expr_std_ap': np.nanstd(gene_expr_aps),\n",
    "        'gene_ess_ap': np.nanmean(gene_ess_aps), 'gene_ess_std_ap': np.nanstd(gene_ess_aps)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e2a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_late_cross_validation(classifier, data, target, splits, verbose=True):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    y_real = []\n",
    "    y_proba = []\n",
    "    aps = []\n",
    "    \n",
    "    total_splits = len(splits)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for fold_num, (train, test) in enumerate(splits, start=1):\n",
    "        print(f\"Fold {fold_num}: Train size = {len(train)}, Test size = {len(test)}\")\n",
    "        \n",
    "        if len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        y_test = target.iloc[test].values\n",
    "        y_pred_proba = classifier.fit(data.iloc[train], target.iloc[train]).predict_proba(data.iloc[test])[:, 1]\n",
    "\n",
    "        if np.unique(y_test).size < 2:\n",
    "            print(f\"Skipping fold {fold_num} due to insufficient positive/negative samples.\")\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "\n",
    "        aucs.append(safe_roc_auc(y_test, y_pred_proba))\n",
    "        aps.append(safe_average_precision(y_test, y_pred_proba))\n",
    "\n",
    "        y_real.append(y_test)\n",
    "        y_proba.append(y_pred_proba)\n",
    "\n",
    "        if verbose:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Fold {fold_num}/{total_splits} complete: ROC AUC = {aucs[-1]:.4f}, \"\n",
    "                  f\"Elapsed time = {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    if len(tprs) > 0:\n",
    "        mean_tpr = np.mean([np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(tprs))], axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "    else:\n",
    "        mean_tpr, mean_auc, std_auc = np.array([]), np.nan, np.nan\n",
    "    \n",
    "    if len(y_real) > 0 and len(y_proba) > 0:\n",
    "        y_real = np.concatenate(y_real)\n",
    "        y_proba = np.concatenate(y_proba)\n",
    "        precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "    else:\n",
    "        precision, recall = np.array([]), np.array([])\n",
    "\n",
    "    if verbose and not np.isnan(mean_auc):\n",
    "        print(f\"Cross-validation complete: Mean ROC AUC = {mean_auc:.4f}, Std ROC AUC = {std_auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'tprs': tprs, 'fprs': fprs, 'aucs': aucs,\n",
    "        'mean_tpr': mean_tpr, 'mean_fpr': mean_fpr, 'mean_auc': mean_auc, 'std_auc': std_auc,\n",
    "        'precision': precision, 'recall': recall, 'aps': aps,\n",
    "        'mean_aps': np.nanmean(aps), \n",
    "        'std_ap': np.nanstd(aps)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9382c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "data_1 = integrated_training_df_clean[feature_columns_1]\n",
    "data_2 = integrated_training_df_clean[feature_columns_2]\n",
    "target = integrated_training_df_clean[target_column]\n",
    "\n",
    "# Define your Random Forest classifier\n",
    "RF = RandomForestClassifier(n_estimators=600, random_state=8, max_features=0.2, max_depth=20, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d65ead25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of folds\n",
    "nfolds = 5\n",
    "\n",
    "# Generate StratifiedKFold splits\n",
    "kf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=42)\n",
    "splits_I = list(kf.split(integrated_training_df_clean[feature_columns_1], integrated_training_df_clean[target_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbffb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/NEW/imputation/cross_validation/model_I/splits.pkl', 'wb') as f:\n",
    "    pickle.dump(splits_I, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "292cddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 32995, Test size = 8249\n",
      "Fold 1/5 complete: ROC AUC = 0.9101, Elapsed time = 48.08 seconds\n",
      "Fold 2: Train size = 32995, Test size = 8249\n",
      "Fold 2/5 complete: ROC AUC = 0.9180, Elapsed time = 92.66 seconds\n",
      "Fold 3: Train size = 32995, Test size = 8249\n",
      "Fold 3/5 complete: ROC AUC = 0.9246, Elapsed time = 137.19 seconds\n",
      "Fold 4: Train size = 32995, Test size = 8249\n",
      "Fold 4/5 complete: ROC AUC = 0.9158, Elapsed time = 182.06 seconds\n",
      "Fold 5: Train size = 32996, Test size = 8248\n",
      "Fold 5/5 complete: ROC AUC = 0.9283, Elapsed time = 226.58 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9186, Std ROC AUC = 0.0064\n",
      "Fold 1: Train size = 32995, Test size = 8249\n",
      "Fold 1/5 complete: ROC AUC = 0.9203, Elapsed time = 63.83 seconds\n",
      "Fold 2: Train size = 32995, Test size = 8249\n",
      "Fold 2/5 complete: ROC AUC = 0.9346, Elapsed time = 132.41 seconds\n",
      "Fold 3: Train size = 32995, Test size = 8249\n",
      "Fold 3/5 complete: ROC AUC = 0.9395, Elapsed time = 199.64 seconds\n",
      "Fold 4: Train size = 32995, Test size = 8249\n",
      "Fold 4/5 complete: ROC AUC = 0.9288, Elapsed time = 264.32 seconds\n",
      "Fold 5: Train size = 32996, Test size = 8248\n",
      "Fold 5/5 complete: ROC AUC = 0.9407, Elapsed time = 330.19 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9321, Std ROC AUC = 0.0075\n"
     ]
    }
   ],
   "source": [
    "#Run cross-validation on both feature set\n",
    "model_I_early = model_early_cross_validation(RF, data_1, target, splits_I)\n",
    "model_I_late = model_late_cross_validation(RF, data_2, target, splits_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83131560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_I_early, 'wb') as f:\n",
    "   pickle.dump(model_I_early, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_I_late, 'wb') as f:\n",
    "    pickle.dump(model_I_late, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RepeatedStratifiedKFold with 5 folds and 20 repeats\n",
    "#nfolds = 5\n",
    "#n_repeats = 10\n",
    "\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=nfolds, n_repeats=n_repeats, random_state=42)\n",
    "#repeated_splits_I = list(rskf.split(integrated_training_df_clean[feature_columns_1], integrated_training_df_clean[target_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_I/repeated_splits_I.pkl', 'wb') as f:\n",
    "    pickle.dump(repeated_splits_I, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efac73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run cross-validation on both feature set\n",
    "model_I_early_repeated = model_early_cross_validation(RF, data_1, target, repeated_splits_I)\n",
    "model_I_late_repeated = model_late_cross_validation(RF, data_2, target, repeated_splits_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c41322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_I_early_repeated, 'wb') as f:\n",
    "    pickle.dump(model_I_early_repeated, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_I_late_repeated, 'wb') as f:\n",
    "    pickle.dump(model_I_late_repeated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows to keep in the reduced training set\n",
    "desired_train_size = 26130\n",
    "\n",
    "def reduce_train_size(train_index, desired_size):\n",
    "\n",
    "    # If the current training set size is larger than desired, randomly sample\n",
    "    if len(train_index) > desired_size:\n",
    "        reduced_train_index = random.sample(list(train_index), desired_size)\n",
    "        return reduced_train_index\n",
    "    else:\n",
    "        return train_index\n",
    "\n",
    "# Repeated Stratified K-Fold with train size reduction\n",
    "def repeated_stratified_reduced_cv(data, target, n_folds, n_repeats, desired_train_size, random_state=42):\n",
    "    all_reduced_splits = []\n",
    "    rng = random.Random(random_state)  # Ensure reproducibility with the same random state\n",
    "\n",
    "    for repeat in range(n_repeats):\n",
    "        # Generate StratifiedKFold splits for each repeat\n",
    "        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state + repeat)\n",
    "        splits = list(kf.split(data, target))\n",
    "\n",
    "        # Reduce the training size for each fold and store the result\n",
    "        reduced_splits = []\n",
    "        for fold_num, (train_index, test_index) in enumerate(splits, start=1):\n",
    "            # Reduce the train size to the desired number of rows (26,000 in this case)\n",
    "            reduced_train_index = reduce_train_size(train_index, desired_train_size)\n",
    "            \n",
    "            # Store the reduced train and original test indices\n",
    "            reduced_splits.append((reduced_train_index, test_index))\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Repeat {repeat + 1}, Fold {fold_num} - Train size reduced to: {len(reduced_train_index)}, Test size: {len(test_index)}\")\n",
    "\n",
    "        # Add the reduced splits for this repeat to the overall list\n",
    "        all_reduced_splits.extend(reduced_splits)\n",
    "\n",
    "    return all_reduced_splits\n",
    "\n",
    "reduced_splits_I = repeated_stratified_reduced_cv(\n",
    "    data=integrated_training_df_clean[feature_columns_1],\n",
    "    target=integrated_training_df_clean[target_column],\n",
    "    n_folds=5,\n",
    "    n_repeats=10,\n",
    "    desired_train_size=desired_train_size,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_I/reduced_splits_I.pkl', 'wb') as f:\n",
    "    pickle.dump(reduced_splits_I, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9402c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run cross-validation on both feature set\n",
    "model_I_early_reduced = model_early_cross_validation(RF, data_1, target, reduced_splits_I)\n",
    "model_I_late_reduced = model_late_cross_validation(RF, data_2, target, reduced_splits_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_I_early_reduced, 'wb') as f:\n",
    "    pickle.dump(model_I_early_reduced, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_I_late_reduced, 'wb') as f:\n",
    "    pickle.dump(model_I_late_reduced, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a07636",
   "metadata": {},
   "source": [
    "## Model II\n",
    "#### Same paralog pairs, different cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a541835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "TRAIN: group=['PK1_PANCREAS' 'A549_LUNG' 'GI1_CENTRAL_NERVOUS_SYSTEM' 'HS936T_SKIN'\n",
      " 'MELJUSO_SKIN' 'IPC298_SKIN' 'HSC5_SKIN' 'MEL202_UVEA']\n",
      "TEST: group=['PATU8988S_PANCREAS' 'HS944T_SKIN']\n",
      "Fold 2:\n",
      "TRAIN: group=['PATU8988S_PANCREAS' 'PK1_PANCREAS' 'HS944T_SKIN' 'A549_LUNG'\n",
      " 'GI1_CENTRAL_NERVOUS_SYSTEM' 'HS936T_SKIN' 'MELJUSO_SKIN' 'MEL202_UVEA']\n",
      "TEST: group=['IPC298_SKIN' 'HSC5_SKIN']\n",
      "Fold 3:\n",
      "TRAIN: group=['PATU8988S_PANCREAS' 'PK1_PANCREAS' 'HS944T_SKIN'\n",
      " 'GI1_CENTRAL_NERVOUS_SYSTEM' 'HS936T_SKIN' 'MELJUSO_SKIN' 'IPC298_SKIN'\n",
      " 'HSC5_SKIN']\n",
      "TEST: group=['A549_LUNG' 'MEL202_UVEA']\n",
      "Fold 4:\n",
      "TRAIN: group=['PATU8988S_PANCREAS' 'HS944T_SKIN' 'A549_LUNG'\n",
      " 'GI1_CENTRAL_NERVOUS_SYSTEM' 'MELJUSO_SKIN' 'IPC298_SKIN' 'HSC5_SKIN'\n",
      " 'MEL202_UVEA']\n",
      "TEST: group=['PK1_PANCREAS' 'HS936T_SKIN']\n",
      "Fold 5:\n",
      "TRAIN: group=['PATU8988S_PANCREAS' 'PK1_PANCREAS' 'HS944T_SKIN' 'A549_LUNG'\n",
      " 'HS936T_SKIN' 'IPC298_SKIN' 'HSC5_SKIN' 'MEL202_UVEA']\n",
      "TEST: group=['GI1_CENTRAL_NERVOUS_SYSTEM' 'MELJUSO_SKIN']\n"
     ]
    }
   ],
   "source": [
    "# Define group feature for cell lines\n",
    "groups = integrated_training_df_clean['cell_line']\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits_II = list(sgkf.split(integrated_training_df_clean, target, groups))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits_II):\n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f\"TRAIN: group={groups[train_index].unique()}\")\n",
    "    print(f\"TEST: group={groups[test_index].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f85bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/NEW/imputation/cross_validation/model_II/splits_II.pkl', 'wb') as f:\n",
    "    pickle.dump(splits_II, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f36f3d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 32973, Test size = 8271\n",
      "Fold 1/5 complete: ROC AUC = 0.9584, Elapsed time = 43.68 seconds\n",
      "Fold 2: Train size = 32978, Test size = 8266\n",
      "Fold 2/5 complete: ROC AUC = 0.9263, Elapsed time = 86.87 seconds\n",
      "Fold 3: Train size = 33018, Test size = 8226\n",
      "Fold 3/5 complete: ROC AUC = 0.8812, Elapsed time = 131.64 seconds\n",
      "Fold 4: Train size = 32992, Test size = 8252\n",
      "Fold 4/5 complete: ROC AUC = 0.8847, Elapsed time = 174.23 seconds\n",
      "Fold 5: Train size = 33015, Test size = 8229\n",
      "Fold 5/5 complete: ROC AUC = 0.8572, Elapsed time = 216.51 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9012, Std ROC AUC = 0.0361\n",
      "Fold 1: Train size = 32973, Test size = 8271\n",
      "Fold 1/5 complete: ROC AUC = 0.9694, Elapsed time = 63.73 seconds\n",
      "Fold 2: Train size = 32978, Test size = 8266\n",
      "Fold 2/5 complete: ROC AUC = 0.9426, Elapsed time = 126.94 seconds\n",
      "Fold 3: Train size = 33018, Test size = 8226\n",
      "Fold 3/5 complete: ROC AUC = 0.9054, Elapsed time = 193.27 seconds\n",
      "Fold 4: Train size = 32992, Test size = 8252\n",
      "Fold 4/5 complete: ROC AUC = 0.9068, Elapsed time = 255.59 seconds\n",
      "Fold 5: Train size = 33015, Test size = 8229\n",
      "Fold 5/5 complete: ROC AUC = 0.8661, Elapsed time = 317.59 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9172, Std ROC AUC = 0.0353\n"
     ]
    }
   ],
   "source": [
    "model_II_early = model_early_cross_validation(RF, data_1, target, splits_II)\n",
    "model_II_late = model_late_cross_validation(RF, data_2, target, splits_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54020e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_II_early, 'wb') as f:\n",
    "    pickle.dump(model_II_early, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_II_late, 'wb') as f:\n",
    "    pickle.dump(model_II_late, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_stratified_group_kfold(data, target, groups, n_folds, n_repeats=n_repeats, random_state=42):\n",
    "    \n",
    "    all_splits = []\n",
    "    \n",
    "    for repeat in range(n_repeats):\n",
    "        # Set up StratifiedGroupKFold with an incremented random state for each repeat\n",
    "        sgkf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=random_state + repeat)\n",
    "        splits = list(sgkf.split(data, target, groups))\n",
    "        \n",
    "        # Append each split (train_index, test_index) to all_splits\n",
    "        for fold_num, (train_index, test_index) in enumerate(splits, start=1):\n",
    "            all_splits.append((train_index, test_index))\n",
    "            \n",
    "            # Print fold details for tracking\n",
    "            print(f\"Repeat {repeat + 1}, Fold {fold_num}:\")\n",
    "            print(f\"  TRAIN groups: {groups.iloc[train_index].unique()}\")\n",
    "            print(f\"  TEST groups: {groups.iloc[test_index].unique()}\")\n",
    "\n",
    "    return all_splits\n",
    "\n",
    "# Generate the repeated stratified group k-fold splits\n",
    "repeated_splits_II = repeated_stratified_group_kfold(\n",
    "    data=integrated_training_df_clean,\n",
    "    target=target,\n",
    "    groups=groups,\n",
    "    n_folds=5,\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe80e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_II/repeated_splits_II.pkl', 'wb') as f:\n",
    "    pickle.dump(repeated_splits_II, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724cd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run cross-validation on both feature set\n",
    "model_II_early_repeated = model_early_cross_validation(RF, data_1, target, repeated_splits_II)\n",
    "model_II_late_repeated = model_late_cross_validation(RF, data_2, target, repeated_splits_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_II_early_repeated, 'wb') as f:\n",
    "    pickle.dump(model_II_early_repeated, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_II_late_repeated, 'wb') as f:\n",
    "    pickle.dump(model_II_late_repeated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows to keep in the reduced training set\n",
    "desired_train_size = 26130\n",
    "\n",
    "def reduce_train_size(train_index, desired_size):\n",
    "\n",
    "    # If the current training set size is larger than desired, randomly sample\n",
    "    if len(train_index) > desired_size:\n",
    "        reduced_train_index = random.sample(list(train_index), desired_size)\n",
    "        return reduced_train_index\n",
    "    else:\n",
    "        return train_index\n",
    "\n",
    "# Repeated Stratified Group K-Fold with train size reduction\n",
    "def repeated_stratified_group_reduced_cv(data, target, groups, n_folds, n_repeats, desired_train_size, random_state=42):\n",
    "    all_reduced_splits = []\n",
    "    rng = random.Random(random_state)  # Ensure reproducibility with the same random state\n",
    "\n",
    "    for repeat in range(n_repeats):\n",
    "        sgkf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=random_state + repeat)\n",
    "        splits = list(sgkf.split(data, target, groups))\n",
    "\n",
    "        # Reduce the training size for each fold and store the result\n",
    "        reduced_splits = []\n",
    "        for fold_num, (train_index, test_index) in enumerate(splits, start=1):\n",
    "            # Reduce the train size to the desired number of rows (26,000 in this case)\n",
    "            reduced_train_index = reduce_train_size(train_index, desired_train_size)\n",
    "            \n",
    "            # Store the reduced train and original test indices\n",
    "            reduced_splits.append((reduced_train_index, test_index))\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Repeat {repeat + 1}, Fold {fold_num} - Train size reduced to: {len(reduced_train_index)}, Test size: {len(test_index)}\")\n",
    "            print(f\"  TRAIN groups: {groups.iloc[reduced_train_index].unique()}\")\n",
    "            print(f\"  TEST groups: {groups.iloc[test_index].unique()}\")\n",
    "\n",
    "        # Add the reduced splits for this repeat to the overall list\n",
    "        all_reduced_splits.extend(reduced_splits)\n",
    "\n",
    "    return all_reduced_splits\n",
    "\n",
    "reduced_splits_II = repeated_stratified_group_reduced_cv(\n",
    "    data=integrated_training_df_clean,\n",
    "    target=target,\n",
    "    groups=groups,\n",
    "    n_folds=5,\n",
    "    n_repeats=10,\n",
    "    desired_train_size=desired_train_size,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f110ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_II/reduced_splits_II.pkl', 'wb') as f:\n",
    "    pickle.dump(reduced_splits_II, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be844a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_II_early_reduced = model_early_cross_validation(RF, data_1, target, reduced_splits_II)\n",
    "model_II_late_reduced = model_late_cross_validation(RF, data_2, target, reduced_splits_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_II_early_reduced, 'wb') as f:\n",
    "    pickle.dump(model_II_early_reduced, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_II_late_reduced, 'wb') as f:\n",
    "    pickle.dump(model_II_late_reduced, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b1299",
   "metadata": {},
   "source": [
    "## Model III\n",
    "#### Different paralog pairs, same cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a29f7722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "TRAIN: group=10\n",
      "TEST: group=10\n",
      "# of overlapping pairs: 10\n",
      "Fold 2:\n",
      "TRAIN: group=10\n",
      "TEST: group=10\n",
      "# of overlapping pairs: 10\n",
      "Fold 3:\n",
      "TRAIN: group=10\n",
      "TEST: group=10\n",
      "# of overlapping pairs: 10\n",
      "Fold 4:\n",
      "TRAIN: group=10\n",
      "TEST: group=10\n",
      "# of overlapping pairs: 10\n",
      "Fold 5:\n",
      "TRAIN: group=10\n",
      "TEST: group=10\n",
      "# of overlapping pairs: 10\n"
     ]
    }
   ],
   "source": [
    "# Define group feature for gene pairs\n",
    "gene_groups = integrated_training_df_clean['genepair']\n",
    "\n",
    "sgkf2 = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits_III = list(sgkf.split(integrated_training_df_clean, target, gene_groups))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits_III):\n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f\"TRAIN: group={groups[train_index].nunique()}\")\n",
    "    print(f\"TEST: group={groups[test_index].nunique()}\")\n",
    "    print(f'# of overlapping pairs: {np.isin(groups[train_index].unique(), groups[test_index].unique()).sum()}') # True is 1, False is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f2a506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/NEW/imputation/cross_validation/model_III/splits_III.pkl', 'wb') as f:\n",
    "    pickle.dump(splits_III, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cfd584fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 33027, Test size = 8217\n",
      "Fold 1/5 complete: ROC AUC = 0.8739, Elapsed time = 48.31 seconds\n",
      "Fold 2: Train size = 32987, Test size = 8257\n",
      "Fold 2/5 complete: ROC AUC = 0.9121, Elapsed time = 106.06 seconds\n",
      "Fold 3: Train size = 32975, Test size = 8269\n",
      "Fold 3/5 complete: ROC AUC = 0.9168, Elapsed time = 158.55 seconds\n",
      "Fold 4: Train size = 32987, Test size = 8257\n",
      "Fold 4/5 complete: ROC AUC = 0.9171, Elapsed time = 211.62 seconds\n",
      "Fold 5: Train size = 33000, Test size = 8244\n",
      "Fold 5/5 complete: ROC AUC = 0.9050, Elapsed time = 265.65 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9043, Std ROC AUC = 0.0161\n",
      "Fold 1: Train size = 33027, Test size = 8217\n",
      "Fold 1/5 complete: ROC AUC = 0.8865, Elapsed time = 77.53 seconds\n",
      "Fold 2: Train size = 32987, Test size = 8257\n",
      "Fold 2/5 complete: ROC AUC = 0.9078, Elapsed time = 153.94 seconds\n",
      "Fold 3: Train size = 32975, Test size = 8269\n",
      "Fold 3/5 complete: ROC AUC = 0.9218, Elapsed time = 233.43 seconds\n",
      "Fold 4: Train size = 32987, Test size = 8257\n",
      "Fold 4/5 complete: ROC AUC = 0.9214, Elapsed time = 312.99 seconds\n",
      "Fold 5: Train size = 33000, Test size = 8244\n",
      "Fold 5/5 complete: ROC AUC = 0.9046, Elapsed time = 391.36 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.9080, Std ROC AUC = 0.0130\n"
     ]
    }
   ],
   "source": [
    "model_III_early = model_early_cross_validation(RF, data_1, target, splits_III)\n",
    "model_III_late = model_late_cross_validation(RF, data_2, target, splits_III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b100b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_III_early, 'wb') as f:\n",
    "    pickle.dump(model_III_early, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_III_late, 'wb') as f:\n",
    "    pickle.dump(model_III_late, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222de717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the repeated stratified group k-fold splits\n",
    "\n",
    "repeated_splits_III = repeated_stratified_group_kfold(\n",
    "    data=integrated_training_df_clean,\n",
    "    target=target,\n",
    "    groups=gene_groups,\n",
    "    n_folds=5,\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36062117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_III/repeated_splits_III.pkl', 'wb') as f:\n",
    "    pickle.dump(repeated_splits_III, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run cross-validation on both feature set\n",
    "model_III_early_repeated = model_early_cross_validation(RF, data_1, target, repeated_splits_III)\n",
    "model_III_late_repeated = model_late_cross_validation(RF, data_2, target, repeated_splits_III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050275aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_III_early_repeated, 'wb') as f:\n",
    "    pickle.dump(model_III_early_repeated, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_III_late_repeated, 'wb') as f:\n",
    "    pickle.dump(model_III_late_repeated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows to keep in the reduced training set\n",
    "desired_train_size = 26130\n",
    "\n",
    "reduced_splits_III = repeated_stratified_group_reduced_cv(\n",
    "    data=integrated_training_df_clean,\n",
    "    target=target,\n",
    "    groups=gene_groups,\n",
    "    n_folds=5,\n",
    "    n_repeats=10,\n",
    "    desired_train_size=desired_train_size,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb30f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/output/cross_validation/model_III/reduced_splits_III.pkl', 'wb') as f:\n",
    "    pickle.dump(reduced_splits_III, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_III_early_reduced = model_early_cross_validation(RF, data_1, target, reduced_splits_III)\n",
    "model_III_late_reduced = model_late_cross_validation(RF, data_2, target, reduced_splits_III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993158be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_III_early_reduced, 'wb') as f:\n",
    "    pickle.dump(model_III_early_reduced, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_III_late_reduced, 'wb') as f:\n",
    "    pickle.dump(model_III_late_reduced, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b0825",
   "metadata": {},
   "source": [
    "## Model IV\n",
    "#### Different paralog pairs, different cell lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b7b7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Safe metric wrappers ---\n",
    "def safe_roc_auc(y_true, y_score):\n",
    "    mask = ~np.isnan(y_score)\n",
    "    if np.sum(mask) < 2 or len(np.unique(y_true[mask])) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true[mask], y_score[mask])\n",
    "\n",
    "def safe_average_precision(y_true, y_score):\n",
    "    mask = ~np.isnan(y_score)\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return average_precision_score(y_true[mask], y_score[mask])\n",
    "\n",
    "# --- Custom split functions ---\n",
    "def create_disjoint_splits(df, n_splits=5, num_test_cell_lines=2, test_gene_fraction=0.25, random_state=None):\n",
    "    splits = []\n",
    "\n",
    "    # Get the unique cell lines and gene pairs\n",
    "    unique_cell_lines = df['DepMap_ID'].unique()\n",
    "    unique_gene_pairs = df['genepair'].unique()\n",
    "\n",
    "    # Set the random seed if provided\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Shuffle and split cell lines and gene pairs into mutually exclusive groups\n",
    "    np.random.shuffle(unique_cell_lines)\n",
    "    cell_line_splits = np.array_split(unique_cell_lines, n_splits)\n",
    "\n",
    "    np.random.shuffle(unique_gene_pairs)\n",
    "    gene_pair_splits = np.array_split(unique_gene_pairs, n_splits)\n",
    "\n",
    "    # Create the splits\n",
    "    for fold in range(n_splits):\n",
    "        test_cell_lines = cell_line_splits[fold]\n",
    "        test_gene_pairs = gene_pair_splits[fold]\n",
    "\n",
    "        train_cell_lines = np.concatenate([cell_line_splits[i] for i in range(n_splits) if i != fold])\n",
    "        train_gene_pairs = np.concatenate([gene_pair_splits[i] for i in range(n_splits) if i != fold])\n",
    "\n",
    "        # Define train/test indices\n",
    "        test_index = df[(df['DepMap_ID'].isin(test_cell_lines)) & (df['genepair'].isin(test_gene_pairs))].index\n",
    "        train_index = df[(df['DepMap_ID'].isin(train_cell_lines)) & (df['genepair'].isin(train_gene_pairs))].index\n",
    "\n",
    "        splits.append((train_index, test_index))\n",
    "\n",
    "        print(f'[Fold {fold+1}] '\n",
    "              f'# pairs (train): {df.loc[train_index, \"genepair\"].nunique()} | '\n",
    "              f'# pairs (test): {df.loc[test_index, \"genepair\"].nunique()} | '\n",
    "              f'# overlapping: {np.isin(df.loc[test_index, \"genepair\"].unique(), df.loc[train_index, \"genepair\"].unique()).sum()} | '\n",
    "              f'# cells (train): {df.loc[train_index, \"DepMap_ID\"].nunique()} | '\n",
    "              f'# cells (test): {df.loc[test_index, \"DepMap_ID\"].nunique()}')\n",
    "\n",
    "    return splits\n",
    "\n",
    "def repeated_custom_cv(df, n_splits=5, n_repeats=3, num_test_cell_lines=2, test_gene_fraction=0.25, random_state=None):\n",
    "    all_splits = []\n",
    "\n",
    "    for repeat in range(n_repeats):\n",
    "        current_seed = random_state + repeat if random_state is not None else None\n",
    "        splits = create_disjoint_splits(\n",
    "            df,\n",
    "            n_splits=n_splits,\n",
    "            num_test_cell_lines=num_test_cell_lines,\n",
    "            test_gene_fraction=test_gene_fraction,\n",
    "            random_state=current_seed\n",
    "        )\n",
    "        all_splits.extend(splits)\n",
    "\n",
    "    return all_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb001292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 830 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 827 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 829 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 831 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 828 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 831 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 827 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 829 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 831 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 825 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 831 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 831 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 1] # pairs (train): 3336 | # pairs (test): 832 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 2] # pairs (train): 3336 | # pairs (test): 829 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 3] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 4] # pairs (train): 3336 | # pairs (test): 834 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n",
      "[Fold 5] # pairs (train): 3336 | # pairs (test): 833 | # overlapping: 0 | # cells (train): 8 | # cells (test): 2\n"
     ]
    }
   ],
   "source": [
    "splits_IV = repeated_custom_cv(df=integrated_training_df_clean, n_splits=5, n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f59263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "with open('/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/SL PRED/NEW/imputation/cross_validation/model_IV/splits_IV.pkl', 'wb') as f:\n",
    "    pickle.dump(splits_IV, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7105637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train size = 26389, Test size = 1651\n",
      "Fold 1/50 complete: ROC AUC = 0.8909, Elapsed time = 34.30 seconds\n",
      "Fold 2: Train size = 26403, Test size = 1651\n",
      "Fold 2/50 complete: ROC AUC = 0.8416, Elapsed time = 72.95 seconds\n",
      "Fold 3: Train size = 26371, Test size = 1659\n",
      "Fold 3/50 complete: ROC AUC = 0.8924, Elapsed time = 113.43 seconds\n",
      "Fold 4: Train size = 26358, Test size = 1658\n",
      "Fold 4/50 complete: ROC AUC = 0.8562, Elapsed time = 153.84 seconds\n",
      "Fold 5: Train size = 26465, Test size = 1635\n",
      "Fold 5/50 complete: ROC AUC = 0.9318, Elapsed time = 190.60 seconds\n",
      "Fold 6: Train size = 26421, Test size = 1638\n",
      "Fold 6/50 complete: ROC AUC = 0.8349, Elapsed time = 231.25 seconds\n",
      "Fold 7: Train size = 26410, Test size = 1645\n",
      "Fold 7/50 complete: ROC AUC = 0.8899, Elapsed time = 270.97 seconds\n",
      "Fold 8: Train size = 26386, Test size = 1655\n",
      "Fold 8/50 complete: ROC AUC = 0.8565, Elapsed time = 310.16 seconds\n",
      "Fold 9: Train size = 26375, Test size = 1652\n",
      "Fold 9/50 complete: ROC AUC = 0.8711, Elapsed time = 345.97 seconds\n",
      "Fold 10: Train size = 26384, Test size = 1654\n",
      "Fold 10/50 complete: ROC AUC = 0.8349, Elapsed time = 381.47 seconds\n",
      "Fold 11: Train size = 26364, Test size = 1658\n",
      "Fold 11/50 complete: ROC AUC = 0.9238, Elapsed time = 415.91 seconds\n",
      "Fold 12: Train size = 26384, Test size = 1653\n",
      "Fold 12/50 complete: ROC AUC = 0.9153, Elapsed time = 449.79 seconds\n",
      "Fold 13: Train size = 26414, Test size = 1654\n",
      "Fold 13/50 complete: ROC AUC = 0.8941, Elapsed time = 486.87 seconds\n",
      "Fold 14: Train size = 26402, Test size = 1642\n",
      "Fold 14/50 complete: ROC AUC = 0.8607, Elapsed time = 524.52 seconds\n",
      "Fold 15: Train size = 26416, Test size = 1641\n",
      "Fold 15/50 complete: ROC AUC = 0.8318, Elapsed time = 561.27 seconds\n",
      "Fold 16: Train size = 26365, Test size = 1659\n",
      "Fold 16/50 complete: ROC AUC = 0.7709, Elapsed time = 599.32 seconds\n",
      "Fold 17: Train size = 26380, Test size = 1653\n",
      "Fold 17/50 complete: ROC AUC = 0.8803, Elapsed time = 635.99 seconds\n",
      "Fold 18: Train size = 26416, Test size = 1646\n",
      "Fold 18/50 complete: ROC AUC = 0.9144, Elapsed time = 673.90 seconds\n",
      "Fold 19: Train size = 26403, Test size = 1644\n",
      "Fold 19/50 complete: ROC AUC = 0.8987, Elapsed time = 713.82 seconds\n",
      "Fold 20: Train size = 26420, Test size = 1650\n",
      "Fold 20/50 complete: ROC AUC = 0.8857, Elapsed time = 751.56 seconds\n",
      "Fold 21: Train size = 26388, Test size = 1649\n",
      "Fold 21/50 complete: ROC AUC = 0.9108, Elapsed time = 788.53 seconds\n",
      "Fold 22: Train size = 26371, Test size = 1657\n",
      "Fold 22/50 complete: ROC AUC = 0.8794, Elapsed time = 822.40 seconds\n",
      "Fold 23: Train size = 26471, Test size = 1630\n",
      "Fold 23/50 complete: ROC AUC = 0.8911, Elapsed time = 856.29 seconds\n",
      "Fold 24: Train size = 26377, Test size = 1656\n",
      "Fold 24/50 complete: ROC AUC = 0.7867, Elapsed time = 888.88 seconds\n",
      "Fold 25: Train size = 26371, Test size = 1654\n",
      "Fold 25/50 complete: ROC AUC = 0.9070, Elapsed time = 922.16 seconds\n",
      "Fold 26: Train size = 26367, Test size = 1659\n",
      "Fold 26/50 complete: ROC AUC = 0.8691, Elapsed time = 958.42 seconds\n",
      "Fold 27: Train size = 26365, Test size = 1656\n",
      "Fold 27/50 complete: ROC AUC = 0.8008, Elapsed time = 995.63 seconds\n",
      "Fold 28: Train size = 26423, Test size = 1645\n",
      "Fold 28/50 complete: ROC AUC = 0.8727, Elapsed time = 1040.67 seconds\n",
      "Fold 29: Train size = 26395, Test size = 1652\n",
      "Fold 29/50 complete: ROC AUC = 0.8804, Elapsed time = 1081.96 seconds\n",
      "Fold 30: Train size = 26435, Test size = 1641\n",
      "Fold 30/50 complete: ROC AUC = 0.9258, Elapsed time = 1122.35 seconds\n",
      "Fold 31: Train size = 26376, Test size = 1653\n",
      "Fold 31/50 complete: ROC AUC = 0.8974, Elapsed time = 1167.10 seconds\n",
      "Fold 32: Train size = 26409, Test size = 1648\n",
      "Fold 32/50 complete: ROC AUC = 0.9455, Elapsed time = 1209.68 seconds\n",
      "Fold 33: Train size = 26364, Test size = 1653\n",
      "Fold 33/50 complete: ROC AUC = 0.8706, Elapsed time = 1250.72 seconds\n",
      "Fold 34: Train size = 26394, Test size = 1655\n",
      "Fold 34/50 complete: ROC AUC = 0.8248, Elapsed time = 1287.99 seconds\n",
      "Fold 35: Train size = 26435, Test size = 1637\n",
      "Fold 35/50 complete: ROC AUC = 0.8955, Elapsed time = 1336.27 seconds\n",
      "Fold 36: Train size = 26381, Test size = 1657\n",
      "Fold 36/50 complete: ROC AUC = 0.9052, Elapsed time = 1385.55 seconds\n",
      "Fold 37: Train size = 26416, Test size = 1646\n",
      "Fold 37/50 complete: ROC AUC = 0.8103, Elapsed time = 1427.14 seconds\n",
      "Fold 38: Train size = 26367, Test size = 1655\n",
      "Fold 38/50 complete: ROC AUC = 0.9196, Elapsed time = 1467.32 seconds\n",
      "Fold 39: Train size = 26422, Test size = 1645\n",
      "Fold 39/50 complete: ROC AUC = 0.8519, Elapsed time = 1505.78 seconds\n",
      "Fold 40: Train size = 26400, Test size = 1651\n",
      "Fold 40/50 complete: ROC AUC = 0.8772, Elapsed time = 1543.95 seconds\n",
      "Fold 41: Train size = 26359, Test size = 1651\n",
      "Fold 41/50 complete: ROC AUC = 0.8261, Elapsed time = 1581.02 seconds\n",
      "Fold 42: Train size = 26400, Test size = 1647\n",
      "Fold 42/50 complete: ROC AUC = 0.9562, Elapsed time = 1621.72 seconds\n",
      "Fold 43: Train size = 26370, Test size = 1660\n",
      "Fold 43/50 complete: ROC AUC = 0.8003, Elapsed time = 1656.06 seconds\n",
      "Fold 44: Train size = 26439, Test size = 1633\n",
      "Fold 44/50 complete: ROC AUC = 0.8731, Elapsed time = 1693.37 seconds\n",
      "Fold 45: Train size = 26401, Test size = 1646\n",
      "Fold 45/50 complete: ROC AUC = 0.8536, Elapsed time = 1732.98 seconds\n",
      "Fold 46: Train size = 26401, Test size = 1647\n",
      "Fold 46/50 complete: ROC AUC = 0.8231, Elapsed time = 1768.18 seconds\n",
      "Fold 47: Train size = 26427, Test size = 1645\n",
      "Fold 47/50 complete: ROC AUC = 0.9019, Elapsed time = 1803.47 seconds\n",
      "Fold 48: Train size = 26373, Test size = 1653\n",
      "Fold 48/50 complete: ROC AUC = 0.9291, Elapsed time = 1843.00 seconds\n",
      "Fold 49: Train size = 26394, Test size = 1648\n",
      "Fold 49/50 complete: ROC AUC = 0.8797, Elapsed time = 1883.10 seconds\n",
      "Fold 50: Train size = 26385, Test size = 1655\n",
      "Fold 50/50 complete: ROC AUC = 0.8916, Elapsed time = 1923.70 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.8745, Std ROC AUC = 0.0412\n",
      "Fold 1: Train size = 26389, Test size = 1651\n",
      "Fold 1/50 complete: ROC AUC = 0.9077, Elapsed time = 51.43 seconds\n",
      "Fold 2: Train size = 26403, Test size = 1651\n",
      "Fold 2/50 complete: ROC AUC = 0.8623, Elapsed time = 106.06 seconds\n",
      "Fold 3: Train size = 26371, Test size = 1659\n",
      "Fold 3/50 complete: ROC AUC = 0.9204, Elapsed time = 160.39 seconds\n",
      "Fold 4: Train size = 26358, Test size = 1658\n",
      "Fold 4/50 complete: ROC AUC = 0.8603, Elapsed time = 214.28 seconds\n",
      "Fold 5: Train size = 26465, Test size = 1635\n",
      "Fold 5/50 complete: ROC AUC = 0.9466, Elapsed time = 275.52 seconds\n",
      "Fold 6: Train size = 26421, Test size = 1638\n",
      "Fold 6/50 complete: ROC AUC = 0.8505, Elapsed time = 341.15 seconds\n",
      "Fold 7: Train size = 26410, Test size = 1645\n",
      "Fold 7/50 complete: ROC AUC = 0.8972, Elapsed time = 395.50 seconds\n",
      "Fold 8: Train size = 26386, Test size = 1655\n",
      "Fold 8/50 complete: ROC AUC = 0.8913, Elapsed time = 452.89 seconds\n",
      "Fold 9: Train size = 26375, Test size = 1652\n",
      "Fold 9/50 complete: ROC AUC = 0.8843, Elapsed time = 506.05 seconds\n",
      "Fold 10: Train size = 26384, Test size = 1654\n",
      "Fold 10/50 complete: ROC AUC = 0.8534, Elapsed time = 558.22 seconds\n",
      "Fold 11: Train size = 26364, Test size = 1658\n",
      "Fold 11/50 complete: ROC AUC = 0.9264, Elapsed time = 612.68 seconds\n",
      "Fold 12: Train size = 26384, Test size = 1653\n",
      "Fold 12/50 complete: ROC AUC = 0.9033, Elapsed time = 663.26 seconds\n",
      "Fold 13: Train size = 26414, Test size = 1654\n",
      "Fold 13/50 complete: ROC AUC = 0.8894, Elapsed time = 714.65 seconds\n",
      "Fold 14: Train size = 26402, Test size = 1642\n",
      "Fold 14/50 complete: ROC AUC = 0.8819, Elapsed time = 762.17 seconds\n",
      "Fold 15: Train size = 26416, Test size = 1641\n",
      "Fold 15/50 complete: ROC AUC = 0.8316, Elapsed time = 807.47 seconds\n",
      "Fold 16: Train size = 26365, Test size = 1659\n",
      "Fold 16/50 complete: ROC AUC = 0.7783, Elapsed time = 855.31 seconds\n",
      "Fold 17: Train size = 26380, Test size = 1653\n",
      "Fold 17/50 complete: ROC AUC = 0.8951, Elapsed time = 902.65 seconds\n",
      "Fold 18: Train size = 26416, Test size = 1646\n",
      "Fold 18/50 complete: ROC AUC = 0.9066, Elapsed time = 954.54 seconds\n",
      "Fold 19: Train size = 26403, Test size = 1644\n",
      "Fold 19/50 complete: ROC AUC = 0.9083, Elapsed time = 1002.64 seconds\n",
      "Fold 20: Train size = 26420, Test size = 1650\n",
      "Fold 20/50 complete: ROC AUC = 0.8749, Elapsed time = 1052.99 seconds\n",
      "Fold 21: Train size = 26388, Test size = 1649\n",
      "Fold 21/50 complete: ROC AUC = 0.9236, Elapsed time = 1102.67 seconds\n",
      "Fold 22: Train size = 26371, Test size = 1657\n",
      "Fold 22/50 complete: ROC AUC = 0.8899, Elapsed time = 1152.74 seconds\n",
      "Fold 23: Train size = 26471, Test size = 1630\n",
      "Fold 23/50 complete: ROC AUC = 0.9044, Elapsed time = 1203.50 seconds\n",
      "Fold 24: Train size = 26377, Test size = 1656\n",
      "Fold 24/50 complete: ROC AUC = 0.8078, Elapsed time = 1249.65 seconds\n",
      "Fold 25: Train size = 26371, Test size = 1654\n",
      "Fold 25/50 complete: ROC AUC = 0.9258, Elapsed time = 1298.47 seconds\n",
      "Fold 26: Train size = 26367, Test size = 1659\n",
      "Fold 26/50 complete: ROC AUC = 0.8763, Elapsed time = 1348.21 seconds\n",
      "Fold 27: Train size = 26365, Test size = 1656\n",
      "Fold 27/50 complete: ROC AUC = 0.8021, Elapsed time = 1394.73 seconds\n",
      "Fold 28: Train size = 26423, Test size = 1645\n",
      "Fold 28/50 complete: ROC AUC = 0.8825, Elapsed time = 1445.06 seconds\n",
      "Fold 29: Train size = 26395, Test size = 1652\n",
      "Fold 29/50 complete: ROC AUC = 0.8879, Elapsed time = 1496.86 seconds\n",
      "Fold 30: Train size = 26435, Test size = 1641\n",
      "Fold 30/50 complete: ROC AUC = 0.9286, Elapsed time = 1546.50 seconds\n",
      "Fold 31: Train size = 26376, Test size = 1653\n",
      "Fold 31/50 complete: ROC AUC = 0.9051, Elapsed time = 1595.59 seconds\n",
      "Fold 32: Train size = 26409, Test size = 1648\n",
      "Fold 32/50 complete: ROC AUC = 0.9616, Elapsed time = 1645.44 seconds\n",
      "Fold 33: Train size = 26364, Test size = 1653\n",
      "Fold 33/50 complete: ROC AUC = 0.8843, Elapsed time = 1697.99 seconds\n",
      "Fold 34: Train size = 26394, Test size = 1655\n",
      "Fold 34/50 complete: ROC AUC = 0.8482, Elapsed time = 1743.47 seconds\n",
      "Fold 35: Train size = 26435, Test size = 1637\n",
      "Fold 35/50 complete: ROC AUC = 0.9024, Elapsed time = 1792.96 seconds\n",
      "Fold 36: Train size = 26381, Test size = 1657\n",
      "Fold 36/50 complete: ROC AUC = 0.9211, Elapsed time = 1845.18 seconds\n",
      "Fold 37: Train size = 26416, Test size = 1646\n",
      "Fold 37/50 complete: ROC AUC = 0.8422, Elapsed time = 1894.42 seconds\n",
      "Fold 38: Train size = 26367, Test size = 1655\n",
      "Fold 38/50 complete: ROC AUC = 0.9380, Elapsed time = 1945.04 seconds\n",
      "Fold 39: Train size = 26422, Test size = 1645\n",
      "Fold 39/50 complete: ROC AUC = 0.8550, Elapsed time = 1993.57 seconds\n",
      "Fold 40: Train size = 26400, Test size = 1651\n",
      "Fold 40/50 complete: ROC AUC = 0.8678, Elapsed time = 2043.28 seconds\n",
      "Fold 41: Train size = 26359, Test size = 1651\n",
      "Fold 41/50 complete: ROC AUC = 0.8470, Elapsed time = 2092.22 seconds\n",
      "Fold 42: Train size = 26400, Test size = 1647\n",
      "Fold 42/50 complete: ROC AUC = 0.9585, Elapsed time = 2144.19 seconds\n",
      "Fold 43: Train size = 26370, Test size = 1660\n",
      "Fold 43/50 complete: ROC AUC = 0.8198, Elapsed time = 2191.17 seconds\n",
      "Fold 44: Train size = 26439, Test size = 1633\n",
      "Fold 44/50 complete: ROC AUC = 0.8940, Elapsed time = 2241.82 seconds\n",
      "Fold 45: Train size = 26401, Test size = 1646\n",
      "Fold 45/50 complete: ROC AUC = 0.8688, Elapsed time = 2294.10 seconds\n",
      "Fold 46: Train size = 26401, Test size = 1647\n",
      "Fold 46/50 complete: ROC AUC = 0.8152, Elapsed time = 2342.21 seconds\n",
      "Fold 47: Train size = 26427, Test size = 1645\n",
      "Fold 47/50 complete: ROC AUC = 0.9249, Elapsed time = 2391.74 seconds\n",
      "Fold 48: Train size = 26373, Test size = 1653\n",
      "Fold 48/50 complete: ROC AUC = 0.9239, Elapsed time = 2441.46 seconds\n",
      "Fold 49: Train size = 26394, Test size = 1648\n",
      "Fold 49/50 complete: ROC AUC = 0.8854, Elapsed time = 2492.05 seconds\n",
      "Fold 50: Train size = 26385, Test size = 1655\n",
      "Fold 50/50 complete: ROC AUC = 0.9061, Elapsed time = 2543.50 seconds\n",
      "Cross-validation complete: Mean ROC AUC = 0.8851, Std ROC AUC = 0.0400\n"
     ]
    }
   ],
   "source": [
    "model_IV_early = model_early_cross_validation(RF, data_1, target, splits_IV)\n",
    "model_IV_late = model_late_cross_validation(RF, data_2, target, splits_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7e6ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of cross validation\n",
    "with open(file_RF_model_IV_early, 'wb') as f:\n",
    "    pickle.dump(model_IV_early, f)\n",
    "\n",
    "\n",
    "with open(file_RF_model_IV_late, 'wb') as f:\n",
    "    pickle.dump(model_IV_late, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(50):\n",
    "    ax = len(splits_IV[i][0])\n",
    "    a.append(ax)\n",
    "    mean_a = np.average(a)\n",
    "\n",
    "mean_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b51e8",
   "metadata": {},
   "source": [
    "## Draw bar plots to visualize the class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39655d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, roc_curve, precision_recall_curve\n",
    "\n",
    "def plot_model_comparison(df, data, target, cv_results_1, cv_results_2, model_1, model_2):\n",
    "    \"\"\"\n",
    "    Visualizes the ROC and PR curves for two models (Context-Specific and Old Classifier).\n",
    "    \n",
    "    Args:\n",
    "    - df: Original dataframe containing 'SL' column (for baseline calculations).\n",
    "    - data: Dataframe with feature values for additional classifiers.\n",
    "    - target: Target column (binary classification).\n",
    "    - cv_results_1: Cross-validation results for the first model.\n",
    "    - cv_results_2: Cross-validation results for the second model.\n",
    "    - model_1: Name of the first model.\n",
    "    - model_2: Name of the second model.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_context('paper')\n",
    "    f, ax = plt.subplots(1, 2, figsize=(8, 4))  # Set figure size\n",
    "\n",
    "    # Model 1: ROC & PR curves (Context-Specific Classifier)\n",
    "    RocCurveDisplay(\n",
    "        fpr=cv_results_1.get('mean_fpr', []), \n",
    "        tpr=cv_results_1.get('mean_tpr', []), \n",
    "        roc_auc=cv_results_1.get('mean_auc', np.nan),\n",
    "        estimator_name=model_1\n",
    "    ).plot(ax=ax[0], alpha=0.8, color='#E64B35B2')\n",
    "\n",
    "    PrecisionRecallDisplay(\n",
    "        precision=cv_results_1.get('precision', []), \n",
    "        recall=cv_results_1.get('recall', []), \n",
    "        average_precision=cv_results_1.get('mean_aps', np.nan),\n",
    "        estimator_name=model_1\n",
    "    ).plot(ax=ax[1], alpha=0.8, color='#E64B35B2')\n",
    "\n",
    "    # Model 2: ROC & PR curves (Old Classifier)\n",
    "    RocCurveDisplay(\n",
    "        fpr=cv_results_2.get('mean_fpr', []), \n",
    "        tpr=cv_results_2.get('mean_tpr', []), \n",
    "        roc_auc=cv_results_2.get('mean_auc', np.nan),\n",
    "        estimator_name=model_2\n",
    "    ).plot(ax=ax[0], alpha=0.8, color='#4DBBD5B2')\n",
    "\n",
    "    PrecisionRecallDisplay(\n",
    "        precision=cv_results_2.get('precision', []), \n",
    "        recall=cv_results_2.get('recall', []), \n",
    "        average_precision=cv_results_2.get('mean_aps', np.nan),\n",
    "        estimator_name=model_2\n",
    "    ).plot(ax=ax[1], alpha=0.8, color='#4DBBD5B2')\n",
    "\n",
    "    # Additional Comparisons: Old Classifier & Sequence Identity\n",
    "    metrics = ['prediction_score', 'max_seq_id']\n",
    "    colors = ['#4DBBD5B2', '#EFC000FF']\n",
    "    labels = ['Old Classifier', 'Sequence Identity']\n",
    "    auc_labels = ['pred_auc', 'seq_auc']\n",
    "    ap_labels = ['pred_ap', 'seq_ap']\n",
    "\n",
    "    for metric, color, label, auc_label, ap_label in zip(metrics, colors, labels, auc_labels, ap_labels):\n",
    "        if metric not in data.columns:\n",
    "            continue  # Skip if the metric column does not exist\n",
    "\n",
    "        # Compute ROC and PR curves\n",
    "        fpr, tpr, _ = roc_curve(target, data[metric])\n",
    "        precision, recall, _ = precision_recall_curve(target, data[metric])\n",
    "\n",
    "        # Plot ROC curve\n",
    "        RocCurveDisplay(\n",
    "            fpr=fpr, tpr=tpr, \n",
    "            roc_auc=cv_results_1.get(auc_label, np.nan), \n",
    "            estimator_name=label\n",
    "        ).plot(ax=ax[0], alpha=0.8, color=color)\n",
    "\n",
    "        # Plot PR curve\n",
    "        PrecisionRecallDisplay(\n",
    "            precision=precision, recall=recall, \n",
    "            average_precision=cv_results_1.get(ap_label, np.nan), \n",
    "            estimator_name=label\n",
    "        ).plot(ax=ax[1], alpha=0.8, color=color)\n",
    "\n",
    "    # Chance line for ROC\n",
    "    ax[0].plot([0, 1], [0, 1], color=\"lightgrey\", linestyle=\"--\", label='Chance (0.50)')\n",
    "    ax[0].set_xlim([-0.025, 1.025])\n",
    "    ax[0].set_ylim([-0.025, 1.025])\n",
    "    ax[0].spines.top.set(visible=False)\n",
    "    ax[0].spines.right.set(visible=False)\n",
    "    ax[0].set_xlabel('False Positive Rate', fontsize=10)\n",
    "    ax[0].set_ylabel('True Positive Rate', fontsize=10)\n",
    "    ax[0].legend(loc='best', fontsize='small')\n",
    "\n",
    "    # Chance line for PR curve (no skill level based on target class distribution)\n",
    "    no_skill = round(df['SL'].mean(), 2)\n",
    "    ax[1].plot([0, 1], [no_skill, no_skill], linestyle='--', color='lightgrey', label=f'Chance ({no_skill:.2f})')\n",
    "    ax[1].set_xlim([-0.025, 1.025])\n",
    "    ax[1].set_ylim([-0.025, 1.025])\n",
    "    ax[1].spines.top.set(visible=False)\n",
    "    ax[1].spines.right.set(visible=False)\n",
    "    ax[1].set_xlabel('Recall', fontsize=10)\n",
    "    ax[1].set_ylabel('Precision', fontsize=10)\n",
    "    ax[1].legend(loc='best', fontsize='small')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.close(f)  # Uncomment if generating multiple plots to save memory\n",
    "\n",
    "# Example usage:\n",
    "# plot_model_comparison(df, data, target, cv_results, cv_results_v2, '/Users/narod/Desktop', 'Context_Model', 'Old_Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(integrated_training_df, integrated_training_df[['prediction_score', 'max_seq_id']], integrated_training_df['SL'], cv_results, cv_results_II, 'Early Integration', 'Late Integration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa10a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(df, splits, k, title):\n",
    "    percentages_train = []\n",
    "    percentages_test = []\n",
    "    train_sizes = []\n",
    "    test_sizes = []\n",
    "    # Loop through each split and calculate the percentage of True values\n",
    "    for i in range(k):\n",
    "    # Get the subset of the DataFrame based on the split indices\n",
    "        subset1 = df.iloc[splits[i][0]]\n",
    "        subset2 = df.iloc[splits[i][1]]\n",
    "        # Calculate the percentage of True values in the subset\n",
    "        percentage_true_train = (subset1['SL_08'].sum() / len(subset1['SL_08'])) * 100\n",
    "        percentage_true_test = (subset2['SL_08'].sum() / len(subset2['SL_08'])) * 100\n",
    "        # Append the percentage to the list\n",
    "        percentages_train.append(percentage_true_train)\n",
    "        percentages_test.append(percentage_true_test)\n",
    "        train_sizes.append(len(subset1))\n",
    "        test_sizes.append(len(subset2))\n",
    "    width = 0.35\n",
    "    x = np.arange(k)\n",
    "    #define colors\n",
    "    train_color = '#0072B2'\n",
    "    test_color = '#E69F00'\n",
    "    # Create the figure and subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    # Plot 1: Grouped bar chart for percentages\n",
    "    ax1.bar(x - width/2, percentages_train, width, label='Train', color=train_color)\n",
    "    ax1.bar(x + width/2, percentages_test, width, label='Test', color=test_color)\n",
    "    ax1.set_xlabel('Split Number')\n",
    "    ax1.set_ylabel('Percentage of True Values')\n",
    "    ax1.set_title('Percentage of True Values in Train and Test Splits:'+ title)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([f'Split {i}' for i in range(k)])\n",
    "    ax1.bar_label(ax1.containers[0], label_type='edge', fmt='%.2f')\n",
    "    ax1.bar_label(ax1.containers[1], label_type='edge', fmt='%.2f')\n",
    "    ax1.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=2)\n",
    "    # Plot 2: Grouped bar chart for number of rows\n",
    "    ax2.bar(x - width/2, train_sizes, width, label='Train Size', color=train_color)\n",
    "    ax2.bar(x + width/2, test_sizes, width, label='Test Size', color=test_color)\n",
    "    ax2.set_xlabel('Split Number')\n",
    "    ax2.set_ylabel('Number of Rows')\n",
    "    ax2.set_title('Number of Rows in Train and Test Subsets:' + title)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([f'Split {i}' for i in range(k)])\n",
    "    ax2.bar_label(ax2.containers[0], label_type='edge')\n",
    "    ax2.bar_label(ax2.containers[1], label_type='edge')\n",
    "    #ax2.legend()\n",
    "    ax2.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=2)\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef24371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance(integrated_training_df_clean, splits_I, 5, \"Model I\")\n",
    "class_balance(integrated_training_df, reduced_splits_I, 10, \"Model I Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e659db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance(integrated_training_df_clean, splits_II, 5, \"Model 2\")\n",
    "class_balance(integrated_training_df_clean, reduced_splits_II, 10, \"Model 2 Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance(integrated_training_df_clean, splits_III, 5, \"Model 3\")\n",
    "class_balance(integrated_training_df_clean, reduced_splits_III, 10, \"Model 3 Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a474d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_balance(integrated_training_df_clean, splits_IV, 10, \"Model 4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "108b54db869758bb0a2a5fbd6c714c226b8dbd7f123473e4652125cfd3651453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
