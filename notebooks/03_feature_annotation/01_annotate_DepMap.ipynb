{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6475aea",
   "metadata": {},
   "source": [
    "### Annotation of DepMap data to CRISPR screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff00b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b08291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the base directory for the project\n",
    "cwd = os.getcwd()\n",
    "BASE_DIR = os.path.abspath(os.path.join(cwd, \"..\", \"..\"))\n",
    "\n",
    "# build paths inside the repo\n",
    "get_data_path = lambda folders, fname: os.path.normpath(\n",
    "    os.path.join(BASE_DIR, *folders, fname)\n",
    ")\n",
    "\n",
    "depmap_folder_path = get_data_path(['output', 'processed_DepMap22Q4'], '')\n",
    "crispr_screens_path = get_data_path(['output', 'processed_CRISPR_screens'], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5442a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_files(folder):\n",
    "    \"\"\"Return sorted list of CSV file paths and their base names (without extension) from a folder.\"\"\"\n",
    "    csv_files = [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if f.endswith('.csv')\n",
    "    ]\n",
    "    csv_files = sorted(csv_files)\n",
    "    filenames = [os.path.splitext(os.path.basename(f))[0] for f in csv_files]\n",
    "    return csv_files, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa2cc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/common_essentials.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/copy_number_data.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/expression_data.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/gene_effect_data.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/mutation_data.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/zexpression_data.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/zgene_effect_data.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_files, feature_names = get_feature_files(depmap_folder_path)\n",
    "feature_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1c2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the mutation data, adn common essentials from files and filenames\n",
    "remove_idx = [0, 4]\n",
    "ufeature_files = np.delete(feature_files, remove_idx)\n",
    "ufeature_names = np.delete(feature_names, remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2043115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files_from_folder(folder_path):\n",
    "    return sorted([\n",
    "        os.path.join(folder_path, file)\n",
    "        for file in os.listdir(folder_path)\n",
    "        if file.endswith('.csv')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df188713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_harle_df.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_harle_df_CCLE22Q4.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_CCLE22Q4.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_labelled.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_network.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_ranked_ess.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_scored.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_CCLE22Q4.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_labelled.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_network.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_ranked_ess.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_scored.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_CCLE22Q4.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_df.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_df_labelled.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_df_network.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_df_ranked_ess.csv',\n",
       " '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_parrish_df_scored.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pair_files = get_csv_files_from_folder(crispr_screens_path)\n",
    "target_pair_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a93895",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pair_files = [\n",
    "    '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df.csv',\n",
    "    '/Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc193ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_depmap_files(ufiles, cell_lines):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file in ufiles:\n",
    "        filtered_df = pd.read_csv(file, index_col=0, low_memory=False)\n",
    "        filtered_df = filtered_df[filtered_df.index.isin(cell_lines['DepMap_ID'])].reset_index()\n",
    "        filtered_df = filtered_df.rename(columns={\"index\":\"DepMap_ID\"})\n",
    "\n",
    "        # Convert wide format to long format\n",
    "        melt_df = pd.melt(filtered_df.drop([\"cell_name\"], axis=1), \n",
    "                          id_vars=[\"DepMap_ID\"], value_vars=filtered_df.drop([\"cell_name\"], axis=1).columns,\n",
    "                          var_name='entrez_id', value_name='value')\n",
    "        \n",
    "        melt_df = melt_df.astype({'entrez_id':'int'})\n",
    "        melt_df = melt_df.rename(columns={'value': os.path.basename(file).split(\".\")[0]})\n",
    "        results.append(melt_df)\n",
    "        print(f\"Processed {file}\")\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa7f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_features(target_df, processed_features):\n",
    "    df = target_df.copy()\n",
    "\n",
    "    # Annotate A1\n",
    "    for feature_df in processed_features:\n",
    "        df = pd.merge(\n",
    "            df,\n",
    "            feature_df.rename(columns={'entrez_id': 'A1_entrez'}),\n",
    "            on=['DepMap_ID', 'A1_entrez'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'copy_number_data': 'A1_copy_number_data',\n",
    "        'expression_data': 'A1_expression_data',\n",
    "        'gene_effect_data': 'A1_gene_effect_data',\n",
    "        'zexpression_data': 'A1_zexpression_data',\n",
    "        'zgene_effect_data': 'A1_zgene_effect_data'\n",
    "    })\n",
    "\n",
    "    # Annotate A2\n",
    "    for feature_df in processed_features:\n",
    "        df = pd.merge(\n",
    "            df,\n",
    "            feature_df.rename(columns={'entrez_id': 'A2_entrez'}),\n",
    "            on=['DepMap_ID', 'A2_entrez'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'copy_number_data': 'A2_copy_number_data',\n",
    "        'expression_data': 'A2_expression_data',\n",
    "        'gene_effect_data': 'A2_gene_effect_data',\n",
    "        'zexpression_data': 'A2_zexpression_data',\n",
    "        'zgene_effect_data': 'A2_zgene_effect_data'\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3dafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_mutations(mapped_df, mutation_df):\n",
    "    filtered = mutation_df[mutation_df['DepMap_ID'].isin(mapped_df['DepMap_ID'])]\n",
    "    filtered = filtered[['entrez_id', 'DepMap_ID', 'Damaging', 'VariantInfo']].copy()\n",
    "    filtered['VariantInfo'] = 1\n",
    "    filtered = filtered.drop_duplicates(subset=['entrez_id', 'DepMap_ID']).reset_index(drop=True)\n",
    "\n",
    "    # Merge A1 mutations\n",
    "    mapped_df = pd.merge(\n",
    "        mapped_df,\n",
    "        filtered.rename(columns={\n",
    "            'entrez_id': 'A1_entrez',\n",
    "            'VariantInfo': 'A1_mut',\n",
    "            'Damaging': 'A1_Deleterious'\n",
    "        }),\n",
    "        on=['DepMap_ID', 'A1_entrez'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Merge A2 mutations\n",
    "    mapped_df = pd.merge(\n",
    "        mapped_df,\n",
    "        filtered.rename(columns={\n",
    "            'entrez_id': 'A2_entrez',\n",
    "            'VariantInfo': 'A2_mut',\n",
    "            'Damaging': 'A2_Deleterious'\n",
    "        }),\n",
    "        on=['DepMap_ID', 'A2_entrez'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return mapped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37c8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_common_essentials(df, essentials_df):\n",
    "    filtered_df = df[~df[\"A1_entrez\"].isin(essentials_df[\"Essentials\"])] \n",
    "    mut_filtered_df = filtered_df[~filtered_df[\"A2_entrez\"].isin(essentials_df[\"Essentials\"])]\n",
    "    mut_filtered_df = mut_filtered_df.reset_index(drop=True)\n",
    "    return mut_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adb0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/copy_number_data.csv\n",
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/expression_data.csv\n",
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/gene_effect_data.csv\n",
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/zexpression_data.csv\n",
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_DepMap22Q4/zgene_effect_data.csv\n",
      "Processed /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_harle_df.csv with shape: (12272, 21)\n",
      "Final shape: (8658, 25)\n"
     ]
    }
   ],
   "source": [
    "mutation_df = pd.read_csv(feature_files[4], low_memory=False)\n",
    "common_essentials_df = pd.read_csv(feature_files[0], low_memory=False)\n",
    "annotated_datasets = []\n",
    "\n",
    "for i, file in enumerate(target_pair_files):\n",
    "    # Load target pair dataset\n",
    "    target_df = pd.read_csv(file)\n",
    "\n",
    "    # Extract cell lines for that dataset\n",
    "    cell_lines = pd.DataFrame(target_df[\"DepMap_ID\"].unique(), columns=[\"DepMap_ID\"])\n",
    "    \n",
    "    # Process feature files for this dataset's cell lines\n",
    "    processed_features = process_depmap_files(ufeature_files, cell_lines)\n",
    "    \n",
    "    mapped_df = annotate_features(target_df, processed_features)\n",
    "    mapped_df = mapped_df.sort_values(['genepair', 'DepMap_ID'], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Processed {file} with shape: {mapped_df.shape}\")\n",
    "\n",
    "    # Add mutation annotations\n",
    "    mut_mapped_df = annotate_mutations(mapped_df, mutation_df)\n",
    "\n",
    "    # Common essential filtering\n",
    "    final_df = filter_common_essentials(mut_mapped_df, common_essentials_df)\n",
    "\n",
    "    annotated_datasets.append(final_df)\n",
    "    print(f\"Final shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa60ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_features(df):\n",
    "    return df.assign(\n",
    "        zMaxExp_A1A2 = lambda x: np.amax(x[['A1_zexpression_data', 'A2_zexpression_data']], axis=1),\n",
    "        zMinExp_A1A2 = lambda x: np.amin(x[['A1_zexpression_data', 'A2_zexpression_data']], axis=1),\n",
    "\n",
    "        rMaxExp_A1A2 = lambda x: np.amax(x[['A1_expression_data', 'A2_expression_data']], axis=1),\n",
    "        rMinExp_A1A2 = lambda x: np.amin(x[['A1_expression_data', 'A2_expression_data']], axis=1),\n",
    "\n",
    "        max_cn = lambda x: np.amax(x[['A1_copy_number_data', 'A2_copy_number_data']], axis=1),\n",
    "        min_cn = lambda x: np.amin(x[['A1_copy_number_data', 'A2_copy_number_data']], axis=1),\n",
    "\n",
    "        zMaxESS_A1A2 = lambda x: np.amax(x[['A1_zgene_effect_data', 'A2_zgene_effect_data']], axis=1),\n",
    "        zMinESS_A1A2 = lambda x: np.amin(x[['A1_zgene_effect_data', 'A2_zgene_effect_data']], axis=1),\n",
    "\n",
    "        rMaxESS_A1A2 = lambda x: np.amax(x[['A1_gene_effect_data', 'A2_gene_effect_data']], axis=1),\n",
    "        rMinESS_A1A2 = lambda x: np.amin(x[['A1_gene_effect_data', 'A2_gene_effect_data']], axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95e122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (8658, 35)\n"
     ]
    }
   ],
   "source": [
    "final_annotated_datasets = []\n",
    "\n",
    "for df in annotated_datasets:\n",
    "    enriched_df = calculate_pairwise_features(df)\n",
    "    final_annotated_datasets.append(enriched_df)\n",
    "    print(f\"Final shape: {enriched_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e67a12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_mutation_flags(df):\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "    df['A1_Deleterious'] = df['A1_Deleterious'].fillna(0).astype(int)\n",
    "    df['A2_Deleterious'] = df['A2_Deleterious'].fillna(0).astype(int)\n",
    "    df['A1_mut'] = df['A1_mut'].fillna(0).astype(int)\n",
    "    df['A2_mut'] = df['A2_mut'].fillna(0).astype(int)\n",
    "\n",
    "    df['Protein_Altering'] = (df['A1_mut'] + df['A2_mut']).astype(int)\n",
    "    df['Damaging'] = (df['A1_Deleterious'] + df['A2_Deleterious']).astype(int)\n",
    "\n",
    "    # Optional: drop rows with any remaining NaNs\n",
    "    # df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea304cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_final_datasets = []\n",
    "\n",
    "for df in final_annotated_datasets:\n",
    "    cleaned_df = finalize_mutation_flags(df)\n",
    "    cleaned_final_datasets.append(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a39baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows (gene pair - cell line combinations): 8658\n",
      "Number of unique gene pairs: 333\n",
      "Number of unique cell lines: 26\n",
      "Number of unique gene pair - cell line combinations: 8658\n",
      "\n",
      "Sample of the data:\n",
      "    genepair sorted_gene_pair    A1    A2  A1_entrez  A2_entrez   DepMap_ID  \\\n",
      "0  ABL1_ABL2        ABL1|ABL2  ABL1  ABL2         25         27  ACH-000094   \n",
      "1  ABL1_ABL2        ABL1|ABL2  ABL1  ABL2         25         27  ACH-000114   \n",
      "2  ABL1_ABL2        ABL1|ABL2  ABL1  ABL2         25         27  ACH-000138   \n",
      "3  ABL1_ABL2        ABL1|ABL2  ABL1  ABL2         25         27  ACH-000219   \n",
      "4  ABL1_ABL2        ABL1|ABL2  ABL1  ABL2         25         27  ACH-000222   \n",
      "\n",
      "  cell_line  SL org_A1  ... rMaxExp_A1A2  rMinExp_A1A2    max_cn    min_cn  \\\n",
      "0   HPAF-II   0   ABL1  ...     3.308885      2.472488  1.021313  0.910252   \n",
      "1  SU.86.86   0   ABL1  ...     3.165108      2.827819  1.053462  0.770505   \n",
      "2   CFPAC-1   0   ABL1  ...     3.654206      3.389567  1.088474  0.736387   \n",
      "3     A-375   0   ABL1  ...     4.852498      4.364572  1.337064  1.012146   \n",
      "4    AsPC-1   0   ABL1  ...     4.078097      2.563158  1.160107  0.791254   \n",
      "\n",
      "   zMaxESS_A1A2  zMinESS_A1A2  rMaxESS_A1A2  rMinESS_A1A2  Protein_Altering  \\\n",
      "0      0.071127     -0.280014      0.061556     -0.010937                 0   \n",
      "1      0.370810     -0.053685      0.122304     -0.031649                 0   \n",
      "2      0.440928     -0.578396      0.050431      0.033704                 0   \n",
      "3     -0.028295     -0.056327      0.082435     -0.027436                 0   \n",
      "4      0.411237      0.054069      0.126078     -0.013768                 0   \n",
      "\n",
      "   Damaging  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# summary of ito\n",
    "ito = cleaned_final_datasets[0]\n",
    "\n",
    "# Analyze gene pair and cell line triplets in ito2\n",
    "print(f\"Total number of rows (gene pair - cell line combinations): {len(ito)}\")\n",
    "print(f\"Number of unique gene pairs: {ito['genepair'].nunique()}\")\n",
    "print(f\"Number of unique cell lines: {ito['cell_line'].nunique()}\")\n",
    "print(f\"Number of unique gene pair - cell line combinations: {ito[['genepair', 'cell_line']].drop_duplicates().shape[0]}\")\n",
    "\n",
    "# Show some sample data\n",
    "print(\"\\nSample of the data:\")\n",
    "print(ito.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5725362c",
   "metadata": {},
   "source": [
    "### save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "264f10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_ito_df_CCLE22Q4.csv\n",
      "Saved: /Users/narod/Library/CloudStorage/GoogleDrive-narod.kebabci@ucdconnect.ie/My Drive/GitRepos/context_specific_SL_prediction/output/processed_CRISPR_screens/processed_klingbeil_df_CCLE22Q4.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = get_data_path(['output', 'processed_CRISPR_screens'], '')\n",
    "\n",
    "for i, df in enumerate(cleaned_final_datasets):\n",
    "    base_filename = os.path.splitext(os.path.basename(target_pair_files[i]))[0]\n",
    "    output_path = os.path.join(output_dir, f\"{base_filename}_CCLE22Q4.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "108b54db869758bb0a2a5fbd6c714c226b8dbd7f123473e4652125cfd3651453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
